"""
Analysis Runners - Runners consolidados de an√°lisis acad√©mico
Consolida funcionalidad de scripts duplicados reutilizando arquitectura existente.
"""

import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

# A√±adir project root al path
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

import pandas as pd

# Importar sistemas existentes (NO duplicar funcionalidad)
from ml_system.data_acquisition.extractors import ThaiLeagueExtractor
from ml_system.data_processing.processors.batch_processor import BatchProcessor

# Importar utilidades reci√©n creadas
from ml_system.deployment.utils.script_utils import (
    format_execution_time,
    print_data_summary,
    print_header,
    save_analysis_report,
    setup_analysis_logging,
    validate_data_requirements,
)
from ml_system.evaluation.analysis.advanced_features import (
    create_advanced_feature_pipeline,
)
from ml_system.modeling.models.baseline_model import (
    run_advanced_baseline_comparison,
    run_comprehensive_baseline_evaluation,
)

logger = logging.getLogger(__name__)


class AcademicAnalysisRunner:
    """
    Runner consolidado para an√°lisis acad√©micos que REUTILIZA arquitectura existente.
    No duplica funcionalidad, sino que orquesta componentes ya implementados.
    """

    def __init__(self):
        """Inicializa runner con componentes existentes."""
        self.extractor = ThaiLeagueExtractor()
        # self.etl_controller = ETLController()  # Comentado hasta arreglar imports
        self.start_time = datetime.now()

        # Setup logging usando utilidades comunes
        self.logger = setup_analysis_logging("academic_analysis")

    def run_complete_eda_baseline_analysis(self) -> Dict[str, Any]:
        """
        Ejecuta an√°lisis EDA + baseline completo REUTILIZANDO ThaiLeagueExtractor.
        NO duplica la funci√≥n load_thai_league_csv_data() eliminada.

        Returns:
            Dict con resultados del an√°lisis
        """
        try:
            print_header("üéì AN√ÅLISIS EDA + BASELINE ACAD√âMICO COMPLETO", "=", 80)
            self.logger.info(
                "Iniciando an√°lisis EDA + baseline usando arquitectura existente"
            )

            # PASO 1: Cargar datos usando ThaiLeagueExtractor (NO duplicar)
            df = self._load_thai_league_data_efficiently()
            if df is None:
                raise ValueError("No se pudieron cargar datos de Thai League")

            # PASO 2: Validaci√≥n de datos
            validation = validate_data_requirements(
                df,
                required_columns=[
                    "Player",
                    "Age",
                    "Primary position",
                    "Minutes played",
                ],
                min_records=1000,
            )

            if not validation["valid"]:
                self.logger.error(f"Validaci√≥n fall√≥: {validation['errors']}")
                return {"success": False, "errors": validation["errors"]}

            print_data_summary(df, "Dataset Thai League Consolidado")

            # PASO 3: An√°lisis EDA b√°sico
            eda_results = self._run_eda_analysis(df)

            # PASO 4: Evaluaci√≥n baseline usando sistema existente
            baseline_results = self._run_baseline_evaluation_existing()

            # PASO 5: Generar reporte acad√©mico
            report = self._generate_academic_report(eda_results, baseline_results)
            report_file = save_analysis_report(report, "eda_baseline_complete")

            execution_time = format_execution_time(self.start_time)

            results = {
                "success": True,
                "execution_time": execution_time,
                "data_summary": {
                    "records": len(df),
                    "columns": len(df.columns),
                    "seasons": df["season"].nunique() if "season" in df.columns else 1,
                },
                "eda_results": eda_results,
                "baseline_results": baseline_results,
                "report_file": report_file,
                "validation": validation,
            }

            print_header("‚úÖ AN√ÅLISIS COMPLETADO EXITOSAMENTE", "=", 80)
            print(f"üìä Datos procesados: {len(df):,} registros")
            print(f"‚è±Ô∏è  Tiempo de ejecuci√≥n: {execution_time}")
            print(f"üìÅ Reporte guardado en: {report_file}")

            return results

        except Exception as e:
            self.logger.error(f"Error en an√°lisis completo: {e}")
            return {"success": False, "error": str(e)}

    def run_advanced_feature_comparison(self) -> Dict[str, Any]:
        """
        Ejecuta comparaci√≥n de features avanzadas REUTILIZANDO sistema ML existente.
        NO duplica la funci√≥n load_thai_league_data() eliminada.

        Returns:
            Dict con resultados de comparaci√≥n
        """
        try:
            print_header("üöÄ COMPARACI√ìN FEATURES AVANZADAS", "=", 80)
            self.logger.info(
                "Iniciando comparaci√≥n features usando sistema ML existente"
            )

            # PASO 1: Cargar datos (reutilizar)
            df = self._load_thai_league_data_efficiently()
            if df is None:
                raise ValueError("No se pudieron cargar datos")

            # PASO 2: Evaluaci√≥n baseline (usar sistema existente)
            baseline_results = self._run_baseline_evaluation_existing()

            # PASO 3: Comparaci√≥n avanzada (usar sistema existente)
            advanced_results = self._run_advanced_comparison_existing(
                df, baseline_results
            )

            # PASO 4: An√°lisis de importancia de features
            feature_analysis = self._analyze_feature_importance(advanced_results)

            # PASO 5: Generar reporte comparativo
            report = self._generate_comparison_report(
                baseline_results, advanced_results, feature_analysis
            )
            report_file = save_analysis_report(report, "advanced_feature_comparison")

            execution_time = format_execution_time(self.start_time)

            results = {
                "success": True,
                "execution_time": execution_time,
                "baseline_results": baseline_results,
                "advanced_results": advanced_results,
                "feature_analysis": feature_analysis,
                "report_file": report_file,
            }

            print_header("‚úÖ COMPARACI√ìN COMPLETADA", "=", 80)
            print(f"‚è±Ô∏è  Tiempo de ejecuci√≥n: {execution_time}")
            print(f"üìÅ Reporte guardado en: {report_file}")

            return results

        except Exception as e:
            self.logger.error(f"Error en comparaci√≥n avanzada: {e}")
            return {"success": False, "error": str(e)}

    def _load_thai_league_data_efficiently(self) -> Optional[pd.DataFrame]:
        """
        Carga datos Thai League REUTILIZANDO ThaiLeagueExtractor existente.
        Reemplaza las funciones load_thai_league_csv_data() duplicadas eliminadas.
        """
        try:
            self.logger.info("üìä Cargando datos usando ThaiLeagueExtractor")

            # Usar extractor existente para obtener todas las temporadas
            available_seasons = self.extractor.AVAILABLE_SEASONS.keys()
            all_dataframes = []

            for season in available_seasons:
                self.logger.info(f"Cargando temporada {season}...")
                success, df, message = self.extractor.download_season_data(season)

                if success and df is not None:
                    df["season"] = season
                    all_dataframes.append(df)
                    self.logger.info(f"‚úÖ {season}: {len(df):,} registros")
                else:
                    self.logger.warning(f"‚ö†Ô∏è Error en {season}: {message}")

            if not all_dataframes:
                return None

            combined_df = pd.concat(all_dataframes, ignore_index=True)
            self.logger.info(
                f"üìä Dataset consolidado: {len(combined_df):,} registros, {len(combined_df.columns)} columnas"
            )

            return combined_df

        except Exception as e:
            self.logger.error(f"Error cargando datos: {e}")
            return None

    def _run_eda_analysis(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Ejecuta an√°lisis EDA b√°sico."""
        try:
            eda_results = {
                "dataset_info": {
                    "total_records": len(df),
                    "total_columns": len(df.columns),
                    "seasons": (
                        sorted(df["season"].unique()) if "season" in df.columns else []
                    ),
                    "date_range": {
                        "seasons": (
                            df["season"].nunique() if "season" in df.columns else 1
                        )
                    },
                },
                "player_analysis": {},
                "position_analysis": {},
                "quality_analysis": {},
            }

            # An√°lisis de jugadores √∫nicos
            if "Player" in df.columns:
                unique_players = df["Player"].nunique()
                avg_records_per_player = len(df) / unique_players
                eda_results["player_analysis"] = {
                    "unique_players": unique_players,
                    "avg_records_per_player": round(avg_records_per_player, 2),
                }

            # An√°lisis de posiciones
            if "Primary position" in df.columns:
                position_counts = df["Primary position"].value_counts()
                eda_results["position_analysis"] = {
                    "unique_positions": len(position_counts),
                    "top_positions": position_counts.head().to_dict(),
                    "position_distribution": position_counts.to_dict(),
                }

            # An√°lisis de calidad de datos
            null_analysis = df.isnull().sum()
            eda_results["quality_analysis"] = {
                "columns_with_nulls": len(null_analysis[null_analysis > 0]),
                "total_null_values": null_analysis.sum(),
                "null_percentage": (null_analysis.sum() / (len(df) * len(df.columns)))
                * 100,
            }

            return eda_results

        except Exception as e:
            self.logger.error(f"Error en an√°lisis EDA: {e}")
            return {"error": str(e)}

    def _run_baseline_evaluation_existing(self) -> Dict[str, Any]:
        """Ejecuta evaluaci√≥n baseline usando sistema existente."""
        try:
            self.logger.info(
                "üî¨ Ejecutando evaluaci√≥n baseline usando sistema existente"
            )

            # Usar funci√≥n existente de baseline_model.py
            baseline_results = run_comprehensive_baseline_evaluation()

            return baseline_results

        except Exception as e:
            self.logger.error(f"Error en evaluaci√≥n baseline: {e}")
            return {"error": str(e), "models": {}}

    def _run_advanced_comparison_existing(
        self, df: pd.DataFrame, baseline_results: Dict
    ) -> Dict[str, Any]:
        """Ejecuta comparaci√≥n avanzada usando sistema existente."""
        try:
            self.logger.info(
                "üöÄ Ejecutando comparaci√≥n avanzada usando sistema existente"
            )

            # Usar funci√≥n existente de baseline_model.py
            advanced_results = run_advanced_baseline_comparison(df, baseline_results)

            return advanced_results

        except Exception as e:
            self.logger.error(f"Error en comparaci√≥n avanzada: {e}")
            return {"error": str(e)}

    def _analyze_feature_importance(self, advanced_results: Dict) -> Dict[str, Any]:
        """Analiza importancia de features del mejor modelo."""
        try:
            if "best_model" not in advanced_results:
                return {"error": "No se encontr√≥ mejor modelo"}

            best_model_name, best_model_data = advanced_results["best_model"]
            feature_importance = best_model_data.get("Feature_Importance", {})

            if not feature_importance:
                return {"warning": "Modelo no proporciona importancia de features"}

            # Ordenar por importancia
            sorted_features = sorted(
                feature_importance.items(), key=lambda x: x[1], reverse=True
            )

            # Categorizar features
            feature_analysis = {
                "total_features": len(feature_importance),
                "top_10_features": dict(sorted_features[:10]),
                "feature_categories": {
                    "positional": len(
                        [
                            f
                            for f in feature_importance.keys()
                            if "position" in f.lower()
                        ]
                    ),
                    "age_related": len(
                        [f for f in feature_importance.keys() if "age" in f.lower()]
                    ),
                    "tier_related": len(
                        [f for f in feature_importance.keys() if "tier" in f.lower()]
                    ),
                    "interaction": len(
                        [
                            f
                            for f in feature_importance.keys()
                            if "interaction" in f.lower()
                        ]
                    ),
                },
            }

            return feature_analysis

        except Exception as e:
            self.logger.error(f"Error analizando importancia: {e}")
            return {"error": str(e)}

    def _generate_academic_report(
        self, eda_results: Dict, baseline_results: Dict
    ) -> str:
        """Genera reporte acad√©mico consolidado."""
        report_lines = [
            "=" * 80,
            "REPORTE ACAD√âMICO: AN√ÅLISIS EDA + BASELINE",
            "=" * 80,
            f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"Dataset: Liga Tailandesa",
            f"Metodolog√≠a: CRISP-DM con rigor acad√©mico",
            "=" * 80,
            "",
        ]

        # Secci√≥n EDA
        if "dataset_info" in eda_results:
            info = eda_results["dataset_info"]
            report_lines.extend(
                [
                    "üìä AN√ÅLISIS EXPLORATORIO DE DATOS:",
                    f"   ‚Ä¢ Total registros: {info.get('total_records', 'N/A'):,}",
                    f"   ‚Ä¢ Total columnas: {info.get('total_columns', 'N/A')}",
                    f"   ‚Ä¢ Temporadas: {len(info.get('seasons', []))}",
                    "",
                ]
            )

        # Secci√≥n Baseline
        if baseline_results and "models" in baseline_results:
            report_lines.extend(
                [
                    "üî¨ RESULTADOS MODELOS BASELINE:",
                    f"   ‚Ä¢ Modelos evaluados: {len(baseline_results.get('models', {}))}",
                    "",
                ]
            )

            # Mejor modelo
            models = baseline_results.get("models", {})
            if models:
                best_model = min(
                    models.items(), key=lambda x: x[1].get("MAE", float("inf"))
                )
                best_name, best_metrics = best_model

                report_lines.extend(
                    [
                        f"üèÜ MEJOR MODELO: {best_name}",
                        f"   ‚Ä¢ MAE: {best_metrics.get('MAE', 'N/A'):.3f}",
                        f"   ‚Ä¢ R¬≤: {best_metrics.get('R¬≤', 'N/A'):.3f}",
                        f"   ‚Ä¢ RMSE: {best_metrics.get('RMSE', 'N/A'):.3f}",
                        "",
                    ]
                )

        # Conclusiones
        report_lines.extend(
            [
                "üí° CONCLUSIONES ACAD√âMICAS:",
                "   ‚Ä¢ An√°lisis EDA completado exitosamente",
                "   ‚Ä¢ Baseline establecido para futuros modelos",
                "   ‚Ä¢ Metodolog√≠a CRISP-DM aplicada correctamente",
                "",
                "üöÄ PR√ìXIMOS PASOS:",
                "   ‚Ä¢ Implementar modelos avanzados",
                "   ‚Ä¢ Optimizaci√≥n de hiperpar√°metros",
                "   ‚Ä¢ Validaci√≥n temporal por temporadas",
                "",
                "=" * 80,
                "FIN DEL REPORTE",
                "=" * 80,
            ]
        )

        return "\n".join(report_lines)

    def _generate_comparison_report(
        self, baseline_results: Dict, advanced_results: Dict, feature_analysis: Dict
    ) -> str:
        """Genera reporte de comparaci√≥n features."""
        report_lines = [
            "=" * 80,
            "REPORTE ACAD√âMICO: COMPARACI√ìN FEATURES AVANZADAS",
            "=" * 80,
            f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "=" * 80,
            "",
        ]

        # Resultados avanzados
        if "best_model" in advanced_results:
            best_name, best_data = advanced_results["best_model"]
            report_lines.extend(
                [
                    "üöÄ RESULTADOS FEATURES AVANZADAS:",
                    f"   ‚Ä¢ Mejor modelo: {best_name}",
                    f"   ‚Ä¢ MAE: {best_data.get('MAE', 'N/A'):.3f}",
                    f"   ‚Ä¢ R¬≤: {best_data.get('R¬≤', 'N/A'):.3f}",
                    f"   ‚Ä¢ MAPE: {best_data.get('MAPE', 'N/A'):.1f}%",
                    "",
                ]
            )

        # An√°lisis de features
        if "top_10_features" in feature_analysis:
            report_lines.extend(["üìä TOP 10 FEATURES M√ÅS IMPORTANTES:", ""])

            for i, (feature, importance) in enumerate(
                feature_analysis["top_10_features"].items(), 1
            ):
                report_lines.append(f"   {i:2d}. {feature}: {importance:.4f}")

            report_lines.append("")

        # Categorizaci√≥n de features
        if "feature_categories" in feature_analysis:
            cats = feature_analysis["feature_categories"]
            report_lines.extend(
                [
                    "üîß CATEGOR√çAS DE FEATURES:",
                    f"   ‚Ä¢ Features posicionales: {cats.get('positional', 0)}",
                    f"   ‚Ä¢ Features de edad: {cats.get('age_related', 0)}",
                    f"   ‚Ä¢ Features de tier: {cats.get('tier_related', 0)}",
                    f"   ‚Ä¢ Features de interacci√≥n: {cats.get('interaction', 0)}",
                    "",
                ]
            )

        # Mejora vs baseline
        if "improvement_vs_baseline" in advanced_results:
            improvement = advanced_results.get("improvement_vs_baseline", 0)
            if improvement:
                report_lines.extend(
                    [
                        "üìà MEJORA VS BASELINE:",
                        f"   ‚Ä¢ Reducci√≥n MAE: {improvement:.3f}",
                        f"   ‚Ä¢ Estado: {'‚úÖ Mejora significativa' if improvement > 0 else '‚ùå Sin mejora'}",
                        "",
                    ]
                )

        report_lines.extend(["=" * 80, "FIN DEL REPORTE", "=" * 80])

        return "\n".join(report_lines)


# Funciones de conveniencia para uso directo
def run_eda_baseline_analysis() -> Dict[str, Any]:
    """
    Funci√≥n de conveniencia para ejecutar an√°lisis EDA + baseline completo.
    Reemplaza el script run_eda_baseline_analysis.py eliminado.
    """
    runner = AcademicAnalysisRunner()
    return runner.run_complete_eda_baseline_analysis()


def run_feature_comparison() -> Dict[str, Any]:
    """
    Funci√≥n de conveniencia para ejecutar comparaci√≥n de features avanzadas.
    Reemplaza el script run_advanced_feature_comparison.py eliminado.
    """
    runner = AcademicAnalysisRunner()
    return runner.run_advanced_feature_comparison()


if __name__ == "__main__":
    # Permitir ejecuci√≥n directa
    import argparse

    parser = argparse.ArgumentParser(description="Academic Analysis Runner")
    parser.add_argument(
        "--analysis",
        choices=["eda", "features", "both"],
        default="both",
        help="Tipo de an√°lisis a ejecutar",
    )

    args = parser.parse_args()

    if args.analysis in ["eda", "both"]:
        print("üéì Ejecutando an√°lisis EDA + baseline...")
        eda_results = run_eda_baseline_analysis()
        print(f"‚úÖ EDA completado: {eda_results.get('success', False)}")

    if args.analysis in ["features", "both"]:
        print("üöÄ Ejecutando comparaci√≥n features avanzadas...")
        feature_results = run_feature_comparison()
        print(f"‚úÖ Comparaci√≥n completada: {feature_results.get('success', False)}")
