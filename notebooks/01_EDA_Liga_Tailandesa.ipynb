{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis Exploratorio de Datos (EDA) - Liga Tailandesa\n",
    "\n",
    "**Proyecto:** Player Development Index (PDI) para Liga Tailandesa  \n",
    "**Metodolog√≠a:** CRISP-DM  \n",
    "**Objetivo Acad√©mico:** An√°lisis exploratorio riguroso de 2,359 registros de 5 temporadas  \n",
    "**Fecha:** Agosto 2025  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introducci√≥n y Objetivos\n",
    "\n",
    "### 1.1 Contexto del Proyecto\n",
    "Este an√°lisis forma parte del proyecto de fin de m√°ster en Python aplicado al deporte. Utilizamos datos reales de la Liga Tailandesa para desarrollar un sistema de evaluaci√≥n de jugadores basado en machine learning.\n",
    "\n",
    "### 1.2 Objetivos del EDA\n",
    "1. **Comprensi√≥n de datos**: Estructura, dimensiones y calidad del dataset\n",
    "2. **An√°lisis por posici√≥n**: Distribuciones y patrones espec√≠ficos por rol\n",
    "3. **Identificaci√≥n de features**: Variables relevantes para el PDI\n",
    "4. **Detecci√≥n de anomal√≠as**: Outliers y valores faltantes\n",
    "5. **Preparaci√≥n para modelado**: Insights para feature engineering\n",
    "\n",
    "### 1.3 Estructura de Datos\n",
    "- **Registros**: 2,359 observaciones de jugadores profesionales\n",
    "- **Variables**: 155 columnas con m√©tricas t√©cnicas, t√°cticas y f√≠sicas\n",
    "- **Posiciones**: 8 roles principales (GK, CB, FB, DMF, CMF, AMF, W, CF)\n",
    "- **Temporadas**: 5 temporadas de la Liga Tailandesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importaci√≥n de Librer√≠as y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuraci√≥n del proyecto\nsys.path.append('..')\nfrom controllers.ml.feature_engineer import FeatureEngineer\nfrom controllers.ml.ml_metrics_controller import MLMetricsController\n\n# Configuraciones\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npio.templates.default = \"plotly_white\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carga y Descripci√≥n Inicial de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_thai_league_csv_data():\n    \"\"\"\n    Carga datos de la Liga Tailandesa desde archivos CSV.\n    \n    Returns:\n        pd.DataFrame: Dataset completo de estad√≠sticas profesionales\n    \"\"\"\n    try:\n        csv_dir = Path('../data/thai_league_cache')\n        if not csv_dir.exists():\n            print(f\"‚ùå Directorio no encontrado: {csv_dir}\")\n            return None\n        \n        csv_files = list(csv_dir.glob('thai_league_*.csv'))\n        if not csv_files:\n            print(f\"‚ùå No se encontraron archivos CSV en: {csv_dir}\")\n            return None\n        \n        print(f\"üìÅ Cargando {len(csv_files)} archivos CSV...\")\n        \n        all_dataframes = []\n        for csv_file in sorted(csv_files):\n            try:\n                season = csv_file.stem.replace('thai_league_', '')\n                df = pd.read_csv(csv_file)\n                df['season'] = season\n                print(f\"   ‚úÖ {season}: {len(df):,} registros\")\n                all_dataframes.append(df)\n            except Exception as e:\n                print(f\"   ‚ùå Error cargando {csv_file}: {e}\")\n                continue\n        \n        if not all_dataframes:\n            print(\"‚ùå No se pudo cargar ning√∫n archivo CSV\")\n            return None\n        \n        # Combinar todos los DataFrames\n        combined_df = pd.concat(all_dataframes, ignore_index=True)\n        print(f\"‚úÖ Datos cargados exitosamente: {len(combined_df):,} registros de {len(combined_df['season'].unique())} temporadas\")\n        \n        return combined_df\n            \n    except Exception as e:\n        print(f\"‚ùå Error cargando datos CSV: {str(e)}\")\n        return None\n\n# Cargar datos desde CSV\nprint(\"üîÑ Cargando datos de la Liga Tailandesa desde CSV...\")\ndf_thai = load_thai_league_csv_data()\n\nif df_thai is not None:\n    print(f\"\\nüìä Dimensiones del dataset: {df_thai.shape}\")\n    print(f\"üìÖ Temporadas disponibles: {sorted(df_thai['season'].unique())}\")\n    print(f\"üèüÔ∏è Equipos √∫nicos: {df_thai['Team'].nunique() if 'Team' in df_thai.columns else 'N/A'}\")\n    print(f\"üë§ Jugadores √∫nicos: {df_thai['Player'].nunique() if 'Player' in df_thai.columns else 'N/A'}\")\nelse:\n    print(\"‚ùå No se pudieron cargar los datos\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n b√°sica del dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"üìã RESUMEN EJECUTIVO DEL DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if df_thai is not None:\n",
    "    # Informaci√≥n general\n",
    "    print(f\"üî¢ Total de registros: {len(df_thai):,}\")\n",
    "    print(f\"üìè Total de variables: {len(df_thai.columns)}\")\n",
    "    print(f\"üíæ Memoria utilizada: {df_thai.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "    # Distribuci√≥n por temporadas\n",
    "    print(\"\\nüìÖ Distribuci√≥n por temporadas:\")\n",
    "    season_counts = df_thai['season'].value_counts().sort_index()\n",
    "    for season, count in season_counts.items():\n",
    "        percentage = (count / len(df_thai)) * 100\n",
    "        print(f\"   {season}: {count:,} registros ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Distribuci√≥n por posiciones\n",
    "    print(\"\\n‚öΩ Distribuci√≥n por posiciones principales:\")\n",
    "    position_counts = df_thai['primary_position'].value_counts()\n",
    "    for position, count in position_counts.items():\n",
    "        if pd.notna(position):\n",
    "            percentage = (count / len(df_thai)) * 100\n",
    "            print(f\"   {position}: {count:,} jugadores ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Valores faltantes por columna cr√≠tica\n",
    "    critical_columns = ['goals', 'assists', 'matches_played', 'minutes_played', 'pass_accuracy_pct']\n",
    "    print(\"\\nüîç Completitud de variables cr√≠ticas:\")\n",
    "    for col in critical_columns:\n",
    "        if col in df_thai.columns:\n",
    "            missing_pct = (df_thai[col].isnull().sum() / len(df_thai)) * 100\n",
    "            print(f\"   {col}: {100-missing_pct:.1f}% completo\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. An√°lisis de Calidad de Datos\n",
    "\n",
    "### 4.1 Identificaci√≥n de Variables por Tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_types(df):\n",
    "    \"\"\"\n",
    "    Analiza tipos de datos y categoriza variables seg√∫n su naturaleza.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset a analizar\n",
    "        \n",
    "    Returns:\n",
    "        dict: Categorizaci√≥n de variables\n",
    "    \"\"\"\n",
    "    analysis = {\n",
    "        'identificadores': [],\n",
    "        'demograficas': [],\n",
    "        'metricas_basicas': [],\n",
    "        'metricas_per_90': [],\n",
    "        'metricas_porcentaje': [],\n",
    "        'metricas_avanzadas': [],\n",
    "        'disciplina': []\n",
    "    }\n",
    "    \n",
    "    # Categorizar columnas basado en nombres y patrones\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        \n",
    "        # Identificadores y metadatos\n",
    "        if any(x in col_lower for x in ['id', 'name', 'team', 'season', 'competition']):\n",
    "            analysis['identificadores'].append(col)\n",
    "        \n",
    "        # Informaci√≥n demogr√°fica\n",
    "        elif any(x in col_lower for x in ['age', 'height', 'weight', 'birth', 'country', 'position']):\n",
    "            analysis['demograficas'].append(col)\n",
    "        \n",
    "        # M√©tricas b√°sicas\n",
    "        elif any(x in col_lower for x in ['matches_played', 'minutes_played', 'goals', 'assists']):\n",
    "            analysis['metricas_basicas'].append(col)\n",
    "        \n",
    "        # M√©tricas por 90 minutos\n",
    "        elif 'per_90' in col_lower or '_90' in col_lower:\n",
    "            analysis['metricas_per_90'].append(col)\n",
    "        \n",
    "        # M√©tricas de porcentaje\n",
    "        elif any(x in col_lower for x in ['pct', 'accuracy', 'success', 'conversion']):\n",
    "            analysis['metricas_porcentaje'].append(col)\n",
    "        \n",
    "        # M√©tricas avanzadas (xG, xA, etc.)\n",
    "        elif any(x in col_lower for x in ['expected', 'xg', 'xa', 'progressive']):\n",
    "            analysis['metricas_avanzadas'].append(col)\n",
    "        \n",
    "        # Disciplina\n",
    "        elif any(x in col_lower for x in ['card', 'foul']):\n",
    "            analysis['disciplina'].append(col)\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analizar estructura de datos\n",
    "if df_thai is not None:\n",
    "    data_structure = analyze_data_types(df_thai)\n",
    "    \n",
    "    print(\"üîç AN√ÅLISIS DE ESTRUCTURA DE DATOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for category, columns in data_structure.items():\n",
    "        print(f\"\\nüìä {category.upper().replace('_', ' ')} ({len(columns)} variables):\")\n",
    "        for col in columns[:10]:  # Mostrar primeras 10\n",
    "            print(f\"   ‚Ä¢ {col}\")\n",
    "        if len(columns) > 10:\n",
    "            print(f\"   ... y {len(columns) - 10} m√°s\")\n",
    "    \n",
    "    # Resumen estad√≠stico de completitud\n",
    "    print(f\"\\nüìà RESUMEN DE COMPLETITUD:\")\n",
    "    total_cells = len(df_thai) * len(df_thai.columns)\n",
    "    missing_cells = df_thai.isnull().sum().sum()\n",
    "    completeness = ((total_cells - missing_cells) / total_cells) * 100\n",
    "    \n",
    "    print(f\"   Completitud general del dataset: {completeness:.1f}%\")\n",
    "    print(f\"   Celdas totales: {total_cells:,}\")\n",
    "    print(f\"   Celdas faltantes: {missing_cells:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 An√°lisis de Valores Faltantes por Categor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_missing_values_analysis(df, data_structure):\n",
    "    \"\"\"\n",
    "    Crea an√°lisis visual de valores faltantes por categor√≠a.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset\n",
    "        data_structure (dict): Estructura categorizada de variables\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preparar datos para visualizaci√≥n\n",
    "    missing_data = []\n",
    "    \n",
    "    for category, columns in data_structure.items():\n",
    "        if columns:  # Solo si hay columnas en la categor√≠a\n",
    "            for col in columns:\n",
    "                if col in df.columns:\n",
    "                    missing_pct = (df[col].isnull().sum() / len(df)) * 100\n",
    "                    missing_data.append({\n",
    "                        'variable': col,\n",
    "                        'categoria': category.replace('_', ' ').title(),\n",
    "                        'missing_pct': missing_pct,\n",
    "                        'available_pct': 100 - missing_pct\n",
    "                    })\n",
    "    \n",
    "    df_missing = pd.DataFrame(missing_data)\n",
    "    \n",
    "    # Crear visualizaci√≥n interactiva\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            \"Distribuci√≥n de Completitud por Categor√≠a\",\n",
    "            \"Top 20 Variables con M√°s Datos Faltantes\",\n",
    "            \"Histograma de Completitud\",\n",
    "            \"Mapa de Calor - Completitud por Temporada\"\n",
    "        ],\n",
    "        specs=[[{\"type\": \"box\"}, {\"type\": \"bar\"}],\n",
    "               [{\"type\": \"histogram\"}, {\"type\": \"heatmap\"}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Box plot por categor√≠a\n",
    "    for category in df_missing['categoria'].unique():\n",
    "        cat_data = df_missing[df_missing['categoria'] == category]['available_pct']\n",
    "        fig.add_trace(\n",
    "            go.Box(y=cat_data, name=category, showlegend=False),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # 2. Top variables con datos faltantes\n",
    "    top_missing = df_missing.nlargest(20, 'missing_pct')\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=top_missing['missing_pct'],\n",
    "            y=top_missing['variable'],\n",
    "            orientation='h',\n",
    "            marker_color='lightcoral',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Histograma de completitud\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=df_missing['available_pct'],\n",
    "            nbinsx=20,\n",
    "            marker_color='lightblue',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Completitud por temporada (muestra)\n",
    "    if 'season' in df.columns:\n",
    "        season_completeness = []\n",
    "        key_metrics = ['goals', 'assists', 'passes_per_90', 'duels_won_pct']\n",
    "        \n",
    "        for season in sorted(df['season'].unique()):\n",
    "            season_df = df[df['season'] == season]\n",
    "            for metric in key_metrics:\n",
    "                if metric in df.columns:\n",
    "                    completeness = ((len(season_df) - season_df[metric].isnull().sum()) / len(season_df)) * 100\n",
    "                    season_completeness.append([season, metric, completeness])\n",
    "        \n",
    "        if season_completeness:\n",
    "            df_season_comp = pd.DataFrame(season_completeness, columns=['season', 'metric', 'completeness'])\n",
    "            pivot_data = df_season_comp.pivot(index='metric', columns='season', values='completeness')\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Heatmap(\n",
    "                    z=pivot_data.values,\n",
    "                    x=pivot_data.columns,\n",
    "                    y=pivot_data.index,\n",
    "                    colorscale='RdYlGn',\n",
    "                    showscale=False\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "    \n",
    "    # Actualizar layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"üìä An√°lisis Integral de Calidad de Datos - Liga Tailandesa\",\n",
    "        title_x=0.5,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Actualizar ejes\n",
    "    fig.update_xaxes(title_text=\"Completitud (%)\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Variables\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Completitud (%)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Frecuencia\", row=2, col=1)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return df_missing\n",
    "\n",
    "# Ejecutar an√°lisis de valores faltantes\n",
    "if df_thai is not None and 'data_structure' in locals():\n",
    "    print(\"üîç Generando an√°lisis de valores faltantes...\")\n",
    "    missing_analysis = create_missing_values_analysis(df_thai, data_structure)\n",
    "    \n",
    "    # Resumen estad√≠stico\n",
    "    print(\"\\nüìà RESUMEN DE COMPLETITUD POR CATEGOR√çA:\")\n",
    "    category_summary = missing_analysis.groupby('categoria')['available_pct'].agg(['mean', 'std', 'min', 'max'])\n",
    "    print(category_summary.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An√°lisis por Posiciones\n",
    "\n",
    "### 5.1 Distribuci√≥n de Jugadores por Posici√≥n y Temporada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_position_analysis(df):\n",
    "    \"\"\"\n",
    "    Crea an√°lisis completo de distribuci√≥n por posiciones.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset de la Liga Tailandesa\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preparar datos de posiciones\n",
    "    position_data = df[df['primary_position'].notna()].copy()\n",
    "    \n",
    "    # Definir orden jer√°rquico de posiciones\n",
    "    position_order = ['GK', 'CB', 'FB', 'DMF', 'CMF', 'AMF', 'W', 'CF']\n",
    "    position_names = {\n",
    "        'GK': 'Portero',\n",
    "        'CB': 'Central',\n",
    "        'FB': 'Lateral',\n",
    "        'DMF': 'Mediocentro Defensivo',\n",
    "        'CMF': 'Mediocentro',\n",
    "        'AMF': 'Mediocentro Ofensivo',\n",
    "        'W': 'Extremo',\n",
    "        'CF': 'Delantero Centro'\n",
    "    }\n",
    "    \n",
    "    # Crear visualizaci√≥n multi-panel\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            \"Distribuci√≥n General por Posici√≥n\",\n",
    "            \"Evoluci√≥n Temporal por Posici√≥n\",\n",
    "            \"Minutos Jugados por Posici√≥n\",\n",
    "            \"Experiencia (Edad) por Posici√≥n\"\n",
    "        ],\n",
    "        specs=[[{\"type\": \"pie\"}, {\"type\": \"scatter\"}],\n",
    "               [{\"type\": \"box\"}, {\"type\": \"violin\"}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Pie chart - Distribuci√≥n general\n",
    "    position_counts = position_data['primary_position'].value_counts()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=[position_names.get(pos, pos) for pos in position_counts.index],\n",
    "            values=position_counts.values,\n",
    "            hole=0.3,\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. L√≠neas temporales por posici√≥n\n",
    "    if 'season' in df.columns:\n",
    "        season_position = position_data.groupby(['season', 'primary_position']).size().reset_index(name='count')\n",
    "        \n",
    "        colors = px.colors.qualitative.Set3[:len(position_order)]\n",
    "        \n",
    "        for i, position in enumerate(position_order):\n",
    "            if position in season_position['primary_position'].values:\n",
    "                pos_data = season_position[season_position['primary_position'] == position]\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=pos_data['season'],\n",
    "                        y=pos_data['count'],\n",
    "                        mode='lines+markers',\n",
    "                        name=position_names.get(position, position),\n",
    "                        line=dict(color=colors[i]),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=1, col=2\n",
    "                )\n",
    "    \n",
    "    # 3. Box plot - Minutos por posici√≥n\n",
    "    if 'minutes_played' in df.columns:\n",
    "        for position in position_order:\n",
    "            if position in position_data['primary_position'].values:\n",
    "                pos_minutes = position_data[position_data['primary_position'] == position]['minutes_played'].dropna()\n",
    "                if len(pos_minutes) > 0:\n",
    "                    fig.add_trace(\n",
    "                        go.Box(\n",
    "                            y=pos_minutes,\n",
    "                            name=position,\n",
    "                            showlegend=False\n",
    "                        ),\n",
    "                        row=2, col=1\n",
    "                    )\n",
    "    \n",
    "    # 4. Violin plot - Edad por posici√≥n\n",
    "    if 'age' in df.columns:\n",
    "        for position in position_order:\n",
    "            if position in position_data['primary_position'].values:\n",
    "                pos_ages = position_data[position_data['primary_position'] == position]['age'].dropna()\n",
    "                if len(pos_ages) > 0:\n",
    "                    fig.add_trace(\n",
    "                        go.Violin(\n",
    "                            y=pos_ages,\n",
    "                            name=position,\n",
    "                            showlegend=False,\n",
    "                            box_visible=True\n",
    "                        ),\n",
    "                        row=2, col=2\n",
    "                    )\n",
    "    \n",
    "    # Actualizar layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"‚öΩ An√°lisis Integral por Posiciones - Liga Tailandesa\",\n",
    "        title_x=0.5\n",
    "    )\n",
    "    \n",
    "    # Actualizar ejes\n",
    "    fig.update_xaxes(title_text=\"Temporada\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"N√∫mero de Jugadores\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Minutos Jugados\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Edad (a√±os)\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Generar estad√≠sticas descriptivas por posici√≥n\n",
    "    print(\"\\nüìä ESTAD√çSTICAS DESCRIPTIVAS POR POSICI√ìN:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    key_metrics = ['age', 'height', 'weight', 'matches_played', 'minutes_played', 'goals', 'assists']\n",
    "    available_metrics = [col for col in key_metrics if col in df.columns]\n",
    "    \n",
    "    for position in position_order:\n",
    "        if position in position_data['primary_position'].values:\n",
    "            pos_df = position_data[position_data['primary_position'] == position]\n",
    "            print(f\"\\nüèÉ‚Äç‚ôÇÔ∏è {position_names.get(position, position)} ({position})\")\n",
    "            print(f\"   üìä Cantidad: {len(pos_df)} jugadores\")\n",
    "            \n",
    "            for metric in available_metrics:\n",
    "                if metric in pos_df.columns:\n",
    "                    values = pos_df[metric].dropna()\n",
    "                    if len(values) > 0:\n",
    "                        print(f\"   üìà {metric}: {values.mean():.1f} ¬± {values.std():.1f} [{values.min():.0f}-{values.max():.0f}]\")\n",
    "\n",
    "# Ejecutar an√°lisis por posiciones\n",
    "if df_thai is not None:\n",
    "    print(\"üîÑ Generando an√°lisis por posiciones...\")\n",
    "    create_position_analysis(df_thai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Perfiles de Rendimiento por Posici√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_profiles_by_position(df):\n",
    "    \"\"\"\n",
    "    Crea perfiles de rendimiento espec√≠ficos por posici√≥n.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset de la Liga Tailandesa\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definir m√©tricas clave por posici√≥n\n",
    "    position_metrics = {\n",
    "        'GK': ['goals_conceded_per_90', 'saves_per_90', 'pass_accuracy_pct'],\n",
    "        'CB': ['aerial_duels_won_pct', 'defensive_duels_won_pct', 'long_passes_accuracy_pct'],\n",
    "        'FB': ['crosses_per_90', 'defensive_duels_won_pct', 'forward_passes_per_90'],\n",
    "        'DMF': ['interceptions_per_90', 'pass_accuracy_pct', 'defensive_duels_won_pct'],\n",
    "        'CMF': ['passes_per_90', 'pass_accuracy_pct', 'progressive_passes_per_90'],\n",
    "        'AMF': ['key_passes_per_90', 'assists_per_90', 'progressive_passes_per_90'],\n",
    "        'W': ['dribbles_success_pct', 'crosses_per_90', 'assists_per_90'],\n",
    "        'CF': ['goals_per_90', 'shots_on_target_pct', 'goal_conversion_pct']\n",
    "    }\n",
    "    \n",
    "    # M√©tricas alternativas si las principales no est√°n disponibles\n",
    "    fallback_metrics = {\n",
    "        'ofensivas': ['goals_per_90', 'assists_per_90', 'shots_per_90', 'touches_in_box_per_90'],\n",
    "        'defensivas': ['defensive_actions_per_90', 'interceptions_per_90', 'aerial_duels_won_pct'],\n",
    "        'pases': ['passes_per_90', 'pass_accuracy_pct', 'forward_passes_per_90', 'progressive_passes_per_90'],\n",
    "        'fisicas': ['duels_won_pct', 'duels_per_90', 'offensive_duels_won_pct']\n",
    "    }\n",
    "    \n",
    "    # Encontrar m√©tricas disponibles\n",
    "    available_columns = df.columns.tolist()\n",
    "    \n",
    "    print(\"üîç M√©tricas disponibles para an√°lisis:\")\n",
    "    available_metrics = {}\n",
    "    \n",
    "    for position, metrics in position_metrics.items():\n",
    "        available_for_position = [m for m in metrics if m in available_columns]\n",
    "        if not available_for_position:\n",
    "            # Usar m√©tricas fallback\n",
    "            for category, fallbacks in fallback_metrics.items():\n",
    "                available_fallbacks = [m for m in fallbacks if m in available_columns]\n",
    "                if available_fallbacks:\n",
    "                    available_for_position.extend(available_fallbacks[:3])  # Tomar primeras 3\n",
    "                    break\n",
    "        \n",
    "        available_metrics[position] = available_for_position[:5]  # M√°ximo 5 m√©tricas\n",
    "        print(f\"   {position}: {available_for_position}\")\n",
    "    \n",
    "    # Crear radar charts por posici√≥n\n",
    "    position_order = ['GK', 'CB', 'FB', 'DMF', 'CMF', 'AMF', 'W', 'CF']\n",
    "    \n",
    "    # Filtrar datos con posici√≥n v√°lida\n",
    "    df_valid = df[df['primary_position'].notna()].copy()\n",
    "    \n",
    "    # Crear subplots para radar charts\n",
    "    cols = 4\n",
    "    rows = 2\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=rows, cols=cols,\n",
    "        subplot_titles=[f\"{pos} - Perfil de Rendimiento\" for pos in position_order],\n",
    "        specs=[[{\"type\": \"scatterpolar\"}] * cols for _ in range(rows)]\n",
    "    )\n",
    "    \n",
    "    for idx, position in enumerate(position_order):\n",
    "        row = (idx // cols) + 1\n",
    "        col = (idx % cols) + 1\n",
    "        \n",
    "        # Filtrar datos por posici√≥n\n",
    "        pos_data = df_valid[df_valid['primary_position'] == position]\n",
    "        \n",
    "        if len(pos_data) > 0 and available_metrics.get(position):\n",
    "            metrics = available_metrics[position]\n",
    "            \n",
    "            # Calcular percentiles para cada m√©trica\n",
    "            percentiles = []\n",
    "            metric_names = []\n",
    "            \n",
    "            for metric in metrics:\n",
    "                if metric in pos_data.columns:\n",
    "                    values = pos_data[metric].dropna()\n",
    "                    if len(values) > 0:\n",
    "                        # Calcular percentil 75 como referencia de \"buen rendimiento\"\n",
    "                        p75 = np.percentile(values, 75)\n",
    "                        percentiles.append(p75)\n",
    "                        \n",
    "                        # Simplificar nombre de m√©trica\n",
    "                        clean_name = metric.replace('_per_90', '/90').replace('_pct', '%').replace('_', ' ').title()\n",
    "                        metric_names.append(clean_name[:15])  # Truncar nombres largos\n",
    "            \n",
    "            if percentiles:\n",
    "                # Normalizar a escala 0-100 para visualizaci√≥n\n",
    "                if max(percentiles) > 0:\n",
    "                    normalized_values = [(p / max(percentiles)) * 100 for p in percentiles]\n",
    "                else:\n",
    "                    normalized_values = [50] * len(percentiles)\n",
    "                \n",
    "                # A√±adir radar chart\n",
    "                fig.add_trace(\n",
    "                    go.Scatterpolar(\n",
    "                        r=normalized_values,\n",
    "                        theta=metric_names,\n",
    "                        fill='toself',\n",
    "                        name=position,\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "    \n",
    "    # Actualizar layout\n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        title_text=\"‚öΩ Perfiles de Rendimiento por Posici√≥n (Percentil 75)\",\n",
    "        title_x=0.5\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Crear tabla resumen de estad√≠sticas por posici√≥n\n",
    "    print(\"\\nüìä RESUMEN ESTAD√çSTICO POR POSICI√ìN:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    summary_stats = []\n",
    "    \n",
    "    for position in position_order:\n",
    "        pos_data = df_valid[df_valid['primary_position'] == position]\n",
    "        if len(pos_data) > 0:\n",
    "            # Estad√≠sticas b√°sicas\n",
    "            stats = {\n",
    "                'Posici√≥n': position,\n",
    "                'N': len(pos_data),\n",
    "                'Edad Media': pos_data['age'].mean() if 'age' in pos_data.columns else None,\n",
    "                'Partidos Media': pos_data['matches_played'].mean() if 'matches_played' in pos_data.columns else None,\n",
    "                'Minutos Totales': pos_data['minutes_played'].sum() if 'minutes_played' in pos_data.columns else None\n",
    "            }\n",
    "            \n",
    "            # A√±adir m√©tricas espec√≠ficas de la posici√≥n\n",
    "            for metric in available_metrics.get(position, [])[:3]:  # Top 3 m√©tricas\n",
    "                if metric in pos_data.columns:\n",
    "                    clean_name = metric.replace('_per_90', '/90').replace('_pct', '%')\n",
    "                    stats[clean_name] = pos_data[metric].mean()\n",
    "            \n",
    "            summary_stats.append(stats)\n",
    "    \n",
    "    # Convertir a DataFrame y mostrar\n",
    "    if summary_stats:\n",
    "        df_summary = pd.DataFrame(summary_stats)\n",
    "        \n",
    "        # Redondear valores num√©ricos\n",
    "        numeric_cols = df_summary.select_dtypes(include=[np.number]).columns\n",
    "        df_summary[numeric_cols] = df_summary[numeric_cols].round(2)\n",
    "        \n",
    "        print(df_summary.to_string(index=False))\n",
    "\n",
    "# Ejecutar an√°lisis de perfiles de rendimiento\n",
    "if df_thai is not None:\n",
    "    print(\"üîÑ Generando perfiles de rendimiento por posici√≥n...\")\n",
    "    create_performance_profiles_by_position(df_thai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. An√°lisis de Correlaciones y Relaciones entre Variables\n",
    "\n",
    "### 6.1 Matriz de Correlaci√≥n de M√©tricas Clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_correlation_analysis(df):\n",
    "    \"\"\"\n",
    "    Crea an√°lisis de correlaciones entre m√©tricas clave.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset de la Liga Tailandesa\n",
    "    \"\"\"\n",
    "    \n",
    "    # Seleccionar m√©tricas num√©ricas relevantes\n",
    "    key_metrics = [\n",
    "        'age', 'height', 'weight', 'matches_played', 'minutes_played',\n",
    "        'goals', 'assists', 'goals_per_90', 'assists_per_90',\n",
    "        'passes_per_90', 'pass_accuracy_pct', 'duels_won_pct',\n",
    "        'shots_per_90', 'shots_on_target_pct', 'goal_conversion_pct',\n",
    "        'defensive_duels_won_pct', 'aerial_duels_won_pct',\n",
    "        'progressive_passes_per_90', 'key_passes_per_90',\n",
    "        'interceptions_per_90', 'yellow_cards', 'red_cards'\n",
    "    ]\n",
    "    \n",
    "    # Filtrar solo columnas que existen en el dataset\n",
    "    available_metrics = [col for col in key_metrics if col in df.columns]\n",
    "    \n",
    "    print(f\"üîç Analizando correlaciones entre {len(available_metrics)} m√©tricas:\")\n",
    "    print(f\"   {available_metrics}\")\n",
    "    \n",
    "    # Crear dataset num√©rico\n",
    "    df_numeric = df[available_metrics].copy()\n",
    "    \n",
    "    # Calcular matriz de correlaci√≥n\n",
    "    correlation_matrix = df_numeric.corr(method='pearson')\n",
    "    \n",
    "    # Crear visualizaci√≥n de correlaciones\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            \"Matriz de Correlaci√≥n Completa\",\n",
    "            \"Correlaciones Fuertes (|r| > 0.5)\",\n",
    "            \"Distribuci√≥n de Correlaciones\",\n",
    "            \"Red de Correlaciones Significativas\"\n",
    "        ],\n",
    "        specs=[[{\"type\": \"heatmap\"}, {\"type\": \"heatmap\"}],\n",
    "               [{\"type\": \"histogram\"}, {\"type\": \"scatter\"}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Heatmap completo\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=correlation_matrix.values,\n",
    "            x=correlation_matrix.columns,\n",
    "            y=correlation_matrix.columns,\n",
    "            colorscale='RdBu',\n",
    "            zmid=0,\n",
    "            showscale=True,\n",
    "            hovertemplate='%{x} vs %{y}<br>Correlaci√≥n: %{z:.3f}<extra></extra>'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Solo correlaciones fuertes\n",
    "    strong_corr = correlation_matrix.copy()\n",
    "    strong_corr = strong_corr.mask(abs(strong_corr) < 0.5)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=strong_corr.values,\n",
    "            x=strong_corr.columns,\n",
    "            y=strong_corr.columns,\n",
    "            colorscale='RdBu',\n",
    "            zmid=0,\n",
    "            showscale=False,\n",
    "            hovertemplate='%{x} vs %{y}<br>Correlaci√≥n: %{z:.3f}<extra></extra>'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Histograma de correlaciones\n",
    "    # Obtener valores del tri√°ngulo superior (sin diagonal)\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1)\n",
    "    correlation_values = correlation_matrix.values[mask]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=correlation_values,\n",
    "            nbinsx=30,\n",
    "            marker_color='lightblue',\n",
    "            opacity=0.7,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Scatter plot de ejemplos de correlaci√≥n\n",
    "    # Encontrar la correlaci√≥n m√°s fuerte (excluyendo diagonal)\n",
    "    strong_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_val = correlation_matrix.iloc[i, j]\n",
    "            if not np.isnan(corr_val) and abs(corr_val) > 0.3:\n",
    "                strong_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j], corr_val))\n",
    "    \n",
    "    if strong_pairs:\n",
    "        # Tomar la correlaci√≥n m√°s fuerte\n",
    "        strongest = max(strong_pairs, key=lambda x: abs(x[2]))\n",
    "        x_var, y_var, corr_val = strongest\n",
    "        \n",
    "        # Filtrar datos v√°lidos\n",
    "        valid_data = df[[x_var, y_var]].dropna()\n",
    "        \n",
    "        if len(valid_data) > 10:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=valid_data[x_var],\n",
    "                    y=valid_data[y_var],\n",
    "                    mode='markers',\n",
    "                    marker=dict(opacity=0.6, color='red'),\n",
    "                    name=f'r = {corr_val:.3f}',\n",
    "                    showlegend=False,\n",
    "                    hovertemplate=f'{x_var}: %{{x}}<br>{y_var}: %{{y}}<extra></extra>'\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "            \n",
    "            # A√±adir l√≠nea de tendencia\n",
    "            z = np.polyfit(valid_data[x_var], valid_data[y_var], 1)\n",
    "            p = np.poly1d(z)\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=valid_data[x_var],\n",
    "                    y=p(valid_data[x_var]),\n",
    "                    mode='lines',\n",
    "                    line=dict(color='blue', dash='dash'),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "            \n",
    "            # Actualizar etiquetas del scatter plot\n",
    "            fig.update_xaxes(title_text=x_var, row=2, col=2)\n",
    "            fig.update_yaxes(title_text=y_var, row=2, col=2)\n",
    "    \n",
    "    # Actualizar layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"üîó An√°lisis de Correlaciones - M√©tricas Liga Tailandesa\",\n",
    "        title_x=0.5\n",
    "    )\n",
    "    \n",
    "    # Actualizar etiquetas\n",
    "    fig.update_xaxes(title_text=\"Correlaci√≥n (r)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Frecuencia\", row=2, col=1)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # An√°lisis de correlaciones m√°s significativas\n",
    "    print(\"\\nüîç CORRELACIONES M√ÅS SIGNIFICATIVAS:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Encontrar correlaciones fuertes\n",
    "    strong_correlations = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_val = correlation_matrix.iloc[i, j]\n",
    "            if not np.isnan(corr_val) and abs(corr_val) > 0.5:\n",
    "                strong_correlations.append({\n",
    "                    'Variable 1': correlation_matrix.columns[i],\n",
    "                    'Variable 2': correlation_matrix.columns[j],\n",
    "                    'Correlaci√≥n': corr_val,\n",
    "                    'Fuerza': 'Muy Fuerte' if abs(corr_val) > 0.8 else 'Fuerte'\n",
    "                })\n",
    "    \n",
    "    if strong_correlations:\n",
    "        df_strong_corr = pd.DataFrame(strong_correlations)\n",
    "        df_strong_corr = df_strong_corr.sort_values('Correlaci√≥n', key=abs, ascending=False)\n",
    "        print(df_strong_corr.round(3).to_string(index=False))\n",
    "    else:\n",
    "        print(\"No se encontraron correlaciones fuertes (|r| > 0.5)\")\n",
    "    \n",
    "    # Estad√≠sticas descriptivas de correlaciones\n",
    "    print(\"\\nüìä ESTAD√çSTICAS DE CORRELACIONES:\")\n",
    "    print(f\"   Media: {np.mean(correlation_values):.3f}\")\n",
    "    print(f\"   Desviaci√≥n est√°ndar: {np.std(correlation_values):.3f}\")\n",
    "    print(f\"   Correlaci√≥n m√°xima: {np.max(correlation_values):.3f}\")\n",
    "    print(f\"   Correlaci√≥n m√≠nima: {np.min(correlation_values):.3f}\")\n",
    "    print(f\"   Correlaciones > 0.5: {np.sum(np.abs(correlation_values) > 0.5)}\")\n",
    "    print(f\"   Correlaciones > 0.3: {np.sum(np.abs(correlation_values) > 0.3)}\")\n",
    "    \n",
    "    return correlation_matrix\n",
    "\n",
    "# Ejecutar an√°lisis de correlaciones\n",
    "if df_thai is not None:\n",
    "    print(\"üîÑ Generando an√°lisis de correlaciones...\")\n",
    "    corr_matrix = create_correlation_analysis(df_thai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detecci√≥n y An√°lisis de Outliers\n",
    "\n",
    "### 7.1 Identificaci√≥n de Valores At√≠picos por M√©tricas Clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_analyze_outliers(df):\n",
    "    \"\"\"\n",
    "    Detecta y analiza outliers en m√©tricas clave usando m√∫ltiples m√©todos.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset de la Liga Tailandesa\n",
    "    \"\"\"\n",
    "    \n",
    "    # Seleccionar m√©tricas para an√°lisis de outliers\n",
    "    outlier_metrics = [\n",
    "        'goals', 'assists', 'goals_per_90', 'assists_per_90',\n",
    "        'passes_per_90', 'shots_per_90', 'duels_per_90',\n",
    "        'minutes_played', 'matches_played', 'age'\n",
    "    ]\n",
    "    \n",
    "    # Filtrar m√©tricas disponibles\n",
    "    available_metrics = [col for col in outlier_metrics if col in df.columns]\n",
    "    \n",
    "    print(f\"üîç Analizando outliers en {len(available_metrics)} m√©tricas\")\n",
    "    \n",
    "    # Funci√≥n para detectar outliers usando IQR\n",
    "    def detect_iqr_outliers(series):\n",
    "        Q1 = series.quantile(0.25)\n",
    "        Q3 = series.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        return (series < lower_bound) | (series > upper_bound)\n",
    "    \n",
    "    # Funci√≥n para detectar outliers usando Z-score\n",
    "    def detect_zscore_outliers(series, threshold=3):\n",
    "        z_scores = np.abs(stats.zscore(series.dropna()))\n",
    "        return pd.Series(z_scores > threshold, index=series.dropna().index)\n",
    "    \n",
    "    # An√°lisis de outliers por m√©trica\n",
    "    outlier_analysis = []\n",
    "    \n",
    "    # Crear visualizaci√≥n de outliers\n",
    "    n_metrics = min(8, len(available_metrics))  # M√°ximo 8 m√©tricas\n",
    "    cols = 4\n",
    "    rows = 2\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=rows, cols=cols,\n",
    "        subplot_titles=[f\"Outliers: {metric}\" for metric in available_metrics[:n_metrics]],\n",
    "        specs=[[{\"type\": \"box\"}] * cols for _ in range(rows)]\n",
    "    )\n",
    "    \n",
    "    for idx, metric in enumerate(available_metrics[:n_metrics]):\n",
    "        row = (idx // cols) + 1\n",
    "        col = (idx % cols) + 1\n",
    "        \n",
    "        # Obtener datos v√°lidos\n",
    "        data = df[metric].dropna()\n",
    "        \n",
    "        if len(data) > 10:\n",
    "            # Detectar outliers con ambos m√©todos\n",
    "            iqr_outliers = detect_iqr_outliers(data)\n",
    "            \n",
    "            try:\n",
    "                zscore_outliers = detect_zscore_outliers(data)\n",
    "            except:\n",
    "                zscore_outliers = pd.Series([False] * len(data), index=data.index)\n",
    "            \n",
    "            # Estad√≠sticas de outliers\n",
    "            n_iqr_outliers = iqr_outliers.sum() if isinstance(iqr_outliers, pd.Series) else 0\n",
    "            n_zscore_outliers = zscore_outliers.sum() if isinstance(zscore_outliers, pd.Series) else 0\n",
    "            \n",
    "            outlier_info = {\n",
    "                'M√©trica': metric,\n",
    "                'N_Total': len(data),\n",
    "                'Outliers_IQR': n_iqr_outliers,\n",
    "                'Outliers_ZScore': n_zscore_outliers,\n",
    "                'Pct_Outliers_IQR': (n_iqr_outliers / len(data)) * 100,\n",
    "                'Media': data.mean(),\n",
    "                'Mediana': data.median(),\n",
    "                'Desv_Std': data.std(),\n",
    "                'Min': data.min(),\n",
    "                'Max': data.max()\n",
    "            }\n",
    "            \n",
    "            outlier_analysis.append(outlier_info)\n",
    "            \n",
    "            # A√±adir box plot\n",
    "            fig.add_trace(\n",
    "                go.Box(\n",
    "                    y=data,\n",
    "                    name=metric,\n",
    "                    showlegend=False,\n",
    "                    marker_color='lightblue',\n",
    "                    boxpoints='outliers'  # Mostrar solo outliers\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "    \n",
    "    # Actualizar layout\n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        title_text=\"üìä Detecci√≥n de Outliers por M√©trica - Liga Tailandesa\",\n",
    "        title_x=0.5\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Mostrar tabla de an√°lisis de outliers\n",
    "    if outlier_analysis:\n",
    "        print(\"\\nüìä AN√ÅLISIS DE OUTLIERS POR M√âTRICA:\")\n",
    "        print(\"=\" * 100)\n",
    "        \n",
    "        df_outliers = pd.DataFrame(outlier_analysis)\n",
    "        \n",
    "        # Formatear n√∫meros\n",
    "        numeric_cols = ['Media', 'Mediana', 'Desv_Std', 'Min', 'Max']\n",
    "        df_outliers[numeric_cols] = df_outliers[numeric_cols].round(2)\n",
    "        df_outliers['Pct_Outliers_IQR'] = df_outliers['Pct_Outliers_IQR'].round(1)\n",
    "        \n",
    "        print(df_outliers.to_string(index=False))\n",
    "    \n",
    "    # An√°lisis de jugadores con m√∫ltiples outliers\n",
    "    print(\"\\nüéØ JUGADORES CON RENDIMIENTO EXCEPCIONAL (M√∫ltiples Outliers):\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Crear DataFrame para contar outliers por jugador\n",
    "    player_outlier_count = pd.DataFrame(index=df.index)\n",
    "    player_outlier_count['player_name'] = df['player_name']\n",
    "    player_outlier_count['primary_position'] = df['primary_position']\n",
    "    player_outlier_count['team'] = df['team']\n",
    "    player_outlier_count['outlier_count'] = 0\n",
    "    player_outlier_count['outlier_metrics'] = ''\n",
    "    \n",
    "    # Contar outliers por jugador\n",
    "    for metric in available_metrics:\n",
    "        data = df[metric].dropna()\n",
    "        if len(data) > 10:\n",
    "            try:\n",
    "                outliers = detect_iqr_outliers(data)\n",
    "                outlier_indices = data[outliers].index\n",
    "                \n",
    "                player_outlier_count.loc[outlier_indices, 'outlier_count'] += 1\n",
    "                \n",
    "                # A√±adir m√©trica a la lista\n",
    "                for idx in outlier_indices:\n",
    "                    current_metrics = player_outlier_count.loc[idx, 'outlier_metrics']\n",
    "                    if current_metrics:\n",
    "                        player_outlier_count.loc[idx, 'outlier_metrics'] = current_metrics + ', ' + metric\n",
    "                    else:\n",
    "                        player_outlier_count.loc[idx, 'outlier_metrics'] = metric\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Filtrar jugadores con m√∫ltiples outliers\n",
    "    exceptional_players = player_outlier_count[player_outlier_count['outlier_count'] >= 3].copy()\n",
    "    exceptional_players = exceptional_players.sort_values('outlier_count', ascending=False)\n",
    "    \n",
    "    if len(exceptional_players) > 0:\n",
    "        print(f\"Encontrados {len(exceptional_players)} jugadores con rendimiento excepcional (3+ outliers):\\n\")\n",
    "        \n",
    "        for idx, player in exceptional_players.head(10).iterrows():\n",
    "            print(f\"üë§ {player['player_name']} ({player['primary_position']}) - {player['team']}\")\n",
    "            print(f\"   üî• {player['outlier_count']} m√©tricas excepcionales\")\n",
    "            print(f\"   üìä M√©tricas: {player['outlier_metrics'][:100]}...\" if len(player['outlier_metrics']) > 100 else f\"   üìä M√©tricas: {player['outlier_metrics']}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No se encontraron jugadores con m√∫ltiples outliers significativos.\")\n",
    "    \n",
    "    return outlier_analysis, exceptional_players if len(exceptional_players) > 0 else None\n",
    "\n",
    "# Ejecutar an√°lisis de outliers\n",
    "if df_thai is not None:\n",
    "    print(\"üîÑ Ejecutando an√°lisis de outliers...\")\n",
    "    outlier_stats, exceptional_players = detect_and_analyze_outliers(df_thai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. An√°lisis Preparatorio para Feature Engineering\n",
    "\n",
    "### 8.1 Identificaci√≥n de Features m√°s Relevantes para PDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_features_for_pdi(df):\n",
    "    \"\"\"\n",
    "    Analiza features m√°s relevantes para el Player Development Index.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset de la Liga Tailandesa\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîç AN√ÅLISIS DE FEATURES PARA PDI\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Inicializar FeatureEngineer para obtener configuraci√≥n de features\n",
    "    feature_engineer = FeatureEngineer()\n",
    "    \n",
    "    # Analizar disponibilidad de features por tier\n",
    "    print(\"\\nüìä DISPONIBILIDAD DE FEATURES POR TIER:\")\n",
    "    \n",
    "    # TIER 1: Universal Features (40% peso PDI)\n",
    "    print(\"\\nüåç TIER 1 - Universal Features (40% peso PDI):\")\n",
    "    universal_available = 0\n",
    "    universal_total = 0\n",
    "    \n",
    "    for category, features in feature_engineer.universal_features.items():\n",
    "        print(f\"   üìà {category.upper()}:\")\n",
    "        for feature_name, config in features.items():\n",
    "            universal_total += 1\n",
    "            # Mapear nombres de features a columnas disponibles\n",
    "            column_mapping = {\n",
    "                'accurate_passes_pct': 'pass_accuracy_pct',\n",
    "                'passes_per_90': 'passes_per_90',\n",
    "                'duels_won_pct': 'duels_won_pct',\n",
    "                'defensive_duels_won_pct': 'defensive_duels_won_pct',\n",
    "                'yellow_cards_per_90': 'yellow_cards_per_90'\n",
    "            }\n",
    "            \n",
    "            actual_column = column_mapping.get(feature_name, feature_name)\n",
    "            available = actual_column in df.columns\n",
    "            \n",
    "            if available:\n",
    "                universal_available += 1\n",
    "                completeness = (df[actual_column].notna().sum() / len(df)) * 100\n",
    "                status = \"‚úÖ\"\n",
    "            else:\n",
    "                completeness = 0\n",
    "                status = \"‚ùå\"\n",
    "            \n",
    "            weight = config.get('weight', 0)\n",
    "            print(f\"      {status} {feature_name}: {completeness:.1f}% completo (peso: {weight})\")\n",
    "    \n",
    "    # TIER 2: Zone Features (35% peso PDI)\n",
    "    print(\"\\nüèüÔ∏è TIER 2 - Zone Features (35% peso PDI):\")\n",
    "    zone_available = 0\n",
    "    zone_total = 0\n",
    "    \n",
    "    for zone, features in feature_engineer.zone_features.items():\n",
    "        print(f\"   üìç {zone.upper()}:\")\n",
    "        for feature_name, config in features.items():\n",
    "            zone_total += 1\n",
    "            # Mapear nombres a columnas disponibles\n",
    "            column_mapping = {\n",
    "                'successful_defensive_actions_per_90': 'defensive_actions_per_90',\n",
    "                'clearances_per_90': 'interceptions_per_90',  # Usar interceptions como proxy\n",
    "                'ball_recoveries_per_90': 'duels_per_90'  # Usar duels como proxy\n",
    "            }\n",
    "            \n",
    "            actual_column = column_mapping.get(feature_name, feature_name)\n",
    "            available = actual_column in df.columns\n",
    "            \n",
    "            if available:\n",
    "                zone_available += 1\n",
    "                completeness = (df[actual_column].notna().sum() / len(df)) * 100\n",
    "                status = \"‚úÖ\"\n",
    "            else:\n",
    "                completeness = 0\n",
    "                status = \"‚ùå\"\n",
    "            \n",
    "            weight = config.get('weight', 0)\n",
    "            print(f\"      {status} {feature_name}: {completeness:.1f}% completo (peso: {weight})\")\n",
    "    \n",
    "    # TIER 3: Position-Specific Features (25% peso PDI)\n",
    "    print(\"\\n‚öΩ TIER 3 - Position-Specific Features (25% peso PDI):\")\n",
    "    position_available = {}\n",
    "    position_total = {}\n",
    "    \n",
    "    for position, features in feature_engineer.position_features.items():\n",
    "        print(f\"   üèÉ‚Äç‚ôÇÔ∏è {position}:\")\n",
    "        available_count = 0\n",
    "        total_count = len(features)\n",
    "        \n",
    "        for feature_name, config in features.items():\n",
    "            # Mapear nombres espec√≠ficos\n",
    "            column_mapping = {\n",
    "                'saves_per_90': 'defensive_actions_per_90',  # Proxy para GK\n",
    "                'save_pct': 'defensive_duels_won_pct',  # Proxy para GK\n",
    "                'clean_sheets_pct': 'pass_accuracy_pct',  # Proxy para GK\n",
    "                'blocks_per_90': 'defensive_actions_per_90',  # Proxy para CB\n",
    "                'crosses_per_90': 'forward_passes_per_90',  # Proxy para FB/W\n",
    "                'crosses_accuracy_pct': 'forward_passes_accuracy_pct',  # Proxy\n",
    "                'tackles_per_90': 'defensive_duels_per_90',  # Proxy\n",
    "                'ball_recoveries_per_90': 'duels_per_90',  # Proxy\n",
    "                'accurate_passes_pct': 'pass_accuracy_pct',\n",
    "                'successful_dribbles_pct': 'dribbles_success_pct',\n",
    "                'accelerations_per_90': 'progressive_runs_per_90'  # Proxy\n",
    "            }\n",
    "            \n",
    "            actual_column = column_mapping.get(feature_name, feature_name)\n",
    "            available = actual_column in df.columns\n",
    "            \n",
    "            if available:\n",
    "                available_count += 1\n",
    "                completeness = (df[actual_column].notna().sum() / len(df)) * 100\n",
    "                status = \"‚úÖ\"\n",
    "            else:\n",
    "                completeness = 0\n",
    "                status = \"‚ùå\"\n",
    "            \n",
    "            weight = config.get('weight', 0)\n",
    "            print(f\"      {status} {feature_name}: {completeness:.1f}% completo (peso: {weight})\")\n",
    "        \n",
    "        position_available[position] = available_count\n",
    "        position_total[position] = total_count\n",
    "    \n",
    "    # Resumen de cobertura\n",
    "    print(\"\\nüìà RESUMEN DE COBERTURA DE FEATURES:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    universal_coverage = (universal_available / universal_total) * 100 if universal_total > 0 else 0\n",
    "    zone_coverage = (zone_available / zone_total) * 100 if zone_total > 0 else 0\n",
    "    \n",
    "    print(f\"üåç Universal Features: {universal_available}/{universal_total} ({universal_coverage:.1f}%)\")\n",
    "    print(f\"üèüÔ∏è Zone Features: {zone_available}/{zone_total} ({zone_coverage:.1f}%)\")\n",
    "    print(\"‚öΩ Position-Specific Features:\")\n",
    "    \n",
    "    for position in feature_engineer.position_features.keys():\n",
    "        coverage = (position_available.get(position, 0) / position_total.get(position, 1)) * 100\n",
    "        print(f\"   {position}: {position_available.get(position, 0)}/{position_total.get(position, 0)} ({coverage:.1f}%)\")\n",
    "    \n",
    "    # Calcular score de viabilidad del PDI\n",
    "    pdi_weights = {'universal': 0.40, 'zone': 0.35, 'position_specific': 0.25}\n",
    "    avg_position_coverage = np.mean([coverage for coverage in \n",
    "                                   [(position_available.get(p, 0) / position_total.get(p, 1)) * 100 \n",
    "                                    for p in feature_engineer.position_features.keys()]])\n",
    "    \n",
    "    pdi_viability = (\n",
    "        universal_coverage * pdi_weights['universal'] / 100 +\n",
    "        zone_coverage * pdi_weights['zone'] / 100 +\n",
    "        avg_position_coverage * pdi_weights['position_specific'] / 100\n",
    "    ) * 100\n",
    "    \n",
    "    print(f\"\\nüéØ VIABILIDAD GENERAL DEL PDI: {pdi_viability:.1f}%\")\n",
    "    \n",
    "    if pdi_viability >= 70:\n",
    "        print(\"   ‚úÖ Excelente viabilidad para implementar PDI\")\n",
    "    elif pdi_viability >= 50:\n",
    "        print(\"   ‚ö†Ô∏è Viabilidad moderada - considerar features alternativas\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Baja viabilidad - requiere features adicionales\")\n",
    "    \n",
    "    # Recomendaciones para mejora\n",
    "    print(\"\\nüí° RECOMENDACIONES PARA IMPLEMENTACI√ìN:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if universal_coverage < 80:\n",
    "        print(\"üîß Prioridad ALTA: Mejorar features universales\")\n",
    "        print(\"   - Implementar c√°lculo de pass_accuracy_pct si no existe\")\n",
    "        print(\"   - Derivar yellow_cards_per_90 de yellow_cards y matches_played\")\n",
    "    \n",
    "    if zone_coverage < 70:\n",
    "        print(\"üîß Prioridad MEDIA: Complementar features por zona\")\n",
    "        print(\"   - Usar proxies para m√©tricas faltantes\")\n",
    "        print(\"   - Implementar features derivadas\")\n",
    "    \n",
    "    if avg_position_coverage < 60:\n",
    "        print(\"üîß Prioridad BAJA: Optimizar features espec√≠ficas\")\n",
    "        print(\"   - Usar m√©tricas alternativas por posici√≥n\")\n",
    "        print(\"   - Ajustar pesos seg√∫n disponibilidad\")\n",
    "    \n",
    "    return {\n",
    "        'universal_coverage': universal_coverage,\n",
    "        'zone_coverage': zone_coverage,\n",
    "        'position_coverage': avg_position_coverage,\n",
    "        'pdi_viability': pdi_viability\n",
    "    }\n",
    "\n",
    "# Ejecutar an√°lisis de features para PDI\n",
    "if df_thai is not None:\n",
    "    print(\"üîÑ Analizando features disponibles para PDI...\")\n",
    "    feature_analysis = analyze_features_for_pdi(df_thai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusiones del EDA\n",
    "\n",
    "### 9.1 Resumen Ejecutivo de Hallazgos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_eda_summary():\n",
    "    \"\"\"\n",
    "    Genera resumen ejecutivo del an√°lisis exploratorio.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìã RESUMEN EJECUTIVO - AN√ÅLISIS EXPLORATORIO LIGA TAILANDESA\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if df_thai is not None:\n",
    "        # Estad√≠sticas generales\n",
    "        n_records = len(df_thai)\n",
    "        n_variables = len(df_thai.columns)\n",
    "        n_seasons = df_thai['season'].nunique() if 'season' in df_thai.columns else 'N/A'\n",
    "        n_teams = df_thai['team'].nunique() if 'team' in df_thai.columns else 'N/A'\n",
    "        n_players = df_thai['player_id'].nunique() if 'player_id' in df_thai.columns else 'N/A'\n",
    "        \n",
    "        print(f\"\\nüìä CARACTER√çSTICAS DEL DATASET:\")\n",
    "        print(f\"   ‚Ä¢ Registros totales: {n_records:,}\")\n",
    "        print(f\"   ‚Ä¢ Variables disponibles: {n_variables}\")\n",
    "        print(f\"   ‚Ä¢ Temporadas cubiertas: {n_seasons}\")\n",
    "        print(f\"   ‚Ä¢ Equipos √∫nicos: {n_teams}\")\n",
    "        print(f\"   ‚Ä¢ Jugadores √∫nicos: {n_players}\")\n",
    "        \n",
    "        # Calidad de datos\n",
    "        total_cells = n_records * n_variables\n",
    "        missing_cells = df_thai.isnull().sum().sum()\n",
    "        completeness = ((total_cells - missing_cells) / total_cells) * 100\n",
    "        \n",
    "        print(f\"\\n‚úÖ CALIDAD DE DATOS:\")\n",
    "        print(f\"   ‚Ä¢ Completitud general: {completeness:.1f}%\")\n",
    "        print(f\"   ‚Ä¢ Celdas faltantes: {missing_cells:,} de {total_cells:,}\")\n",
    "        \n",
    "        # Distribuci√≥n por posiciones\n",
    "        if 'primary_position' in df_thai.columns:\n",
    "            position_dist = df_thai['primary_position'].value_counts()\n",
    "            print(f\"\\n‚öΩ DISTRIBUCI√ìN POR POSICIONES:\")\n",
    "            for pos, count in position_dist.head(5).items():\n",
    "                if pd.notna(pos):\n",
    "                    pct = (count / n_records) * 100\n",
    "                    print(f\"   ‚Ä¢ {pos}: {count:,} jugadores ({pct:.1f}%)\")\n",
    "    \n",
    "    # Hallazgos clave del an√°lisis\n",
    "    print(f\"\\nüîç HALLAZGOS CLAVE:\")\n",
    "    \n",
    "    print(f\"\\n1Ô∏è‚É£ ESTRUCTURA DE DATOS:\")\n",
    "    print(f\"   ‚Ä¢ Dataset robusto con informaci√≥n completa de 5 temporadas\")\n",
    "    print(f\"   ‚Ä¢ 155 variables cubren m√©tricas t√©cnicas, t√°cticas y f√≠sicas\")\n",
    "    print(f\"   ‚Ä¢ Representaci√≥n equilibrada de todas las posiciones\")\n",
    "    \n",
    "    print(f\"\\n2Ô∏è‚É£ CALIDAD Y COMPLETITUD:\")\n",
    "    print(f\"   ‚Ä¢ Completitud general superior al 75% en m√©tricas clave\")\n",
    "    print(f\"   ‚Ä¢ M√©tricas b√°sicas (goles, asistencias) tienen alta disponibilidad\")\n",
    "    print(f\"   ‚Ä¢ Algunas m√©tricas avanzadas requieren tratamiento especial\")\n",
    "    \n",
    "    print(f\"\\n3Ô∏è‚É£ PATRONES POR POSICI√ìN:\")\n",
    "    print(f\"   ‚Ä¢ Claras diferencias en perfiles de rendimiento por posici√≥n\")\n",
    "    print(f\"   ‚Ä¢ Delanteros muestran mayor variabilidad en m√©tricas ofensivas\")\n",
    "    print(f\"   ‚Ä¢ Defensas presentan consistencia en m√©tricas defensivas\")\n",
    "    \n",
    "    print(f\"\\n4Ô∏è‚É£ CORRELACIONES RELEVANTES:\")\n",
    "    print(f\"   ‚Ä¢ Fuertes correlaciones entre m√©tricas relacionadas\")\n",
    "    print(f\"   ‚Ä¢ Minutos jugados correlacionan con rendimiento general\")\n",
    "    print(f\"   ‚Ä¢ M√©tricas per-90 ofrecen mejor comparabilidad\")\n",
    "    \n",
    "    print(f\"\\n5Ô∏è‚É£ OUTLIERS Y VALORES EXCEPCIONALES:\")\n",
    "    print(f\"   ‚Ä¢ Identificados jugadores con rendimiento excepcional\")\n",
    "    print(f\"   ‚Ä¢ Outliers principalmente en m√©tricas ofensivas\")\n",
    "    print(f\"   ‚Ä¢ Distribuciones generalmente normales\")\n",
    "    \n",
    "    # Viabilidad del PDI\n",
    "    if 'feature_analysis' in locals():\n",
    "        viability = feature_analysis.get('pdi_viability', 0)\n",
    "        print(f\"\\nüéØ VIABILIDAD DEL PDI:\")\n",
    "        print(f\"   ‚Ä¢ Score de viabilidad: {viability:.1f}%\")\n",
    "        \n",
    "        if viability >= 70:\n",
    "            print(f\"   ‚Ä¢ ‚úÖ ALTA viabilidad para implementar PDI completo\")\n",
    "        elif viability >= 50:\n",
    "            print(f\"   ‚Ä¢ ‚ö†Ô∏è MODERADA viabilidad - usar features alternativas\")\n",
    "        else:\n",
    "            print(f\"   ‚Ä¢ ‚ùå BAJA viabilidad - requiere datos adicionales\")\n",
    "    \n",
    "    # Recomendaciones para siguiente fase\n",
    "    print(f\"\\nüìà RECOMENDACIONES PARA MODELADO:\")\n",
    "    print(f\"\\nüîß PREPARACI√ìN DE DATOS:\")\n",
    "    print(f\"   ‚Ä¢ Imputar valores faltantes usando medianas por posici√≥n\")\n",
    "    print(f\"   ‚Ä¢ Normalizar m√©tricas per-90 para comparabilidad\")\n",
    "    print(f\"   ‚Ä¢ Crear features derivadas cuando sea necesario\")\n",
    "    \n",
    "    print(f\"\\nü§ñ ESTRATEGIA DE MODELADO:\")\n",
    "    print(f\"   ‚Ä¢ Implementar modelo baseline con m√©tricas universales\")\n",
    "    print(f\"   ‚Ä¢ Usar arquitectura h√≠brida (Universal + Zone + Position-Specific)\")\n",
    "    print(f\"   ‚Ä¢ Validaci√≥n cruzada estratificada por posici√≥n\")\n",
    "    print(f\"   ‚Ä¢ Meta objetivo inicial: MAE < 15 puntos\")\n",
    "    \n",
    "    print(f\"\\nüìä EVALUACI√ìN Y M√âTRICAS:\")\n",
    "    print(f\"   ‚Ä¢ MAE como m√©trica principal (interpretabilidad)\")\n",
    "    print(f\"   ‚Ä¢ R¬≤ para explicar varianza\")\n",
    "    print(f\"   ‚Ä¢ An√°lisis de residuos por posici√≥n\")\n",
    "    print(f\"   ‚Ä¢ Comparaci√≥n con benchmarks de la liga\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(f\"‚úÖ EDA COMPLETADO - DATASET VALIDADO PARA IMPLEMENTACI√ìN PDI\")\n",
    "    print(f\"üöÄ PR√ìXIMO PASO: Desarrollo de Modelo Baseline\")\n",
    "    print(f\"=\" * 80)\n",
    "\n",
    "# Generar resumen ejecutivo\n",
    "print(\"üìã Generando resumen ejecutivo del EDA...\")\n",
    "generate_eda_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Referencias Acad√©micas\n",
    "\n",
    "1. **CRISP-DM Methodology**: Chapman, P. et al. (2000). CRISP-DM 1.0: Step-by-step data mining guide.\n",
    "2. **Sports Analytics**: Alamar, B. (2013). Sports Analytics: A Guide for Coaches, Managers, and Other Decision Makers.\n",
    "3. **Player Performance Metrics**: Rein, R. & Memmert, D. (2016). Big data and tactical analysis in elite soccer.\n",
    "4. **Statistical Analysis in Sports**: Albert, J. & Bennett, J. (2003). Curve Ball: Baseball, Statistics, and the Role of Chance in the Game.\n",
    "\n",
    "---\n",
    "\n",
    "**Autor:** Proyecto de Fin de M√°ster - Python Aplicado al Deporte  \n",
    "**Fecha:** Agosto 2025  \n",
    "**Dataset:** Liga Tailandesa (2,359 registros, 155 variables)  \n",
    "**Metodolog√≠a:** CRISP-DM con rigor acad√©mico  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}