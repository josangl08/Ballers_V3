#!/usr/bin/env python3
"""
Script Principal - An√°lisis EDA + Modelo Baseline PDI Liga Tailandesa

Este script ejecuta el pipeline completo de an√°lisis exploratorio y evaluaci√≥n
de modelos baseline para el Player Development Index (PDI) siguiendo metodolog√≠a
CRISP-DM con rigor acad√©mico.

Fases implementadas:
1. An√°lisis Exploratorio de Datos (EDA)
2. Preparaci√≥n de features baseline
3. Entrenamiento y evaluaci√≥n de modelos baseline
4. An√°lisis estad√≠stico comparativo
5. Generaci√≥n de reportes acad√©micos

Objetivo acad√©mico: Establecer baseline s√≥lido con MAE < 15 para futuros modelos.

Autor: Proyecto Fin de M√°ster - Python Aplicado al Deporte
Fecha: Agosto 2025
Dataset: Liga Tailandesa (2,359 registros, 155 variables)
"""

import sys
import os
import logging
import warnings
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional

# Configurar path del proyecto
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# Importaciones del proyecto
try:
    from controllers.ml.baseline_model import (
        LinearBaselineModel, RidgeBaselineModel, EnsembleBaselineModel,
        run_comprehensive_baseline_evaluation
    )
    from controllers.ml.evaluation_pipeline import (
        create_evaluation_pipeline, EvaluationConfig
    )
except ImportError as e:
    print(f"‚ùå Error importando m√≥dulos del proyecto: {e}")
    print("üîß Aseg√∫rate de estar en el directorio correcto del proyecto")
    sys.exit(1)

# Librer√≠as externas
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(f'eda_baseline_analysis_{datetime.now().strftime("%Y%m%d")}.log')
    ]
)
logger = logging.getLogger(__name__)

# Suprimir warnings para output m√°s limpio
warnings.filterwarnings('ignore')


def print_header(title: str, char: str = "=", width: int = 80) -> None:
    """Imprime header acad√©mico formateado."""
    print("\n" + char * width)
    print(f"{title:^{width}}")
    print(char * width)


def load_thai_league_csv_data() -> Optional[pd.DataFrame]:
    """
    Carga todos los CSV de Thai League desde data/thai_league_cache/.
    
    Returns:
        DataFrame combinado con todos los datos o None si falla
    """
    try:
        print_header("üîç CARGANDO DATOS CSV THAI LEAGUE", "=", 60)
        
        csv_dir = Path('data/thai_league_cache')
        if not csv_dir.exists():
            print(f"‚ùå Directorio no encontrado: {csv_dir}")
            return None
        
        csv_files = list(csv_dir.glob('thai_league_*.csv'))
        if not csv_files:
            print(f"‚ùå No se encontraron archivos CSV en: {csv_dir}")
            return None
        
        print(f"üìÅ Archivos CSV encontrados: {len(csv_files)}")
        
        all_dataframes = []
        total_records = 0
        
        for csv_file in sorted(csv_files):
            try:
                season = csv_file.stem.replace('thai_league_', '')
                df = pd.read_csv(csv_file)
                df['season'] = season  # Agregar columna de temporada
                
                print(f"   üìä {season}: {len(df):,} registros, {len(df.columns)} columnas")
                all_dataframes.append(df)
                total_records += len(df)
                
            except Exception as e:
                print(f"   ‚ùå Error cargando {csv_file}: {e}")
                continue
        
        if not all_dataframes:
            print("‚ùå No se pudo cargar ning√∫n archivo CSV")
            return None
        
        # Combinar todos los DataFrames
        combined_df = pd.concat(all_dataframes, ignore_index=True)
        
        print(f"\n‚úÖ DATOS COMBINADOS:")
        print(f"   üìä Total registros: {len(combined_df):,}")
        print(f"   üìä Total columnas: {len(combined_df.columns)}")
        print(f"   üìÖ Temporadas: {len(combined_df['season'].unique())}")
        
        # Mostrar distribuci√≥n por temporada
        season_counts = combined_df['season'].value_counts().sort_index()
        print(f"\nüìà DISTRIBUCI√ìN POR TEMPORADA:")
        for season, count in season_counts.items():
            print(f"   {season}: {count:,} registros")
        
        return combined_df
        
    except Exception as e:
        print(f"‚ùå Error cargando datos CSV: {e}")
        return None


def validate_data_quality(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Valida la calidad de los datos cargados desde CSV usando filtros inteligentes.
    
    Args:
        df: DataFrame con datos de Thai League
        
    Returns:
        Dict con estad√≠sticas de validaci√≥n y DataFrame mejorado
    """
    try:
        print_header("üîç VALIDACI√ìN INTELIGENTE DE DATOS", "=", 60)
        
        # FILTROS DUROS (eliminaci√≥n): solo registros claramente inv√°lidos
        hard_filters = pd.Series([True] * len(df), index=df.index)
        
        if 'Primary position' in df.columns:
            hard_filters = hard_filters & (df['Primary position'].notna())
            
        if 'Minutes played' in df.columns:
            hard_filters = hard_filters & (df['Minutes played'].fillna(0) > 0)
            
        if 'Player' in df.columns:
            hard_filters = hard_filters & (df['Player'].notna())
        
        df_clean = df[hard_filters].copy()
        eliminated = len(df) - len(df_clean)
        print(f"üö´ Registros eliminados (inv√°lidos): {eliminated}")
        
        # SISTEMA DE CONFIANZA: mantener todos pero marcar calidad
        if 'Minutes played' in df_clean.columns:
            # Threshold flexible basado en percentiles
            min_threshold = max(90, df_clean['Minutes played'].quantile(0.05))  # M√≠nimo 1 partido o 5% percentil
            med_threshold = df_clean['Minutes played'].quantile(0.30)  # 30% percentil
            high_threshold = df_clean['Minutes played'].quantile(0.60)  # 60% percentil
            
            # Score de confianza basado en m√∫ltiples factores
            df_clean['minutes_score'] = np.where(
                df_clean['Minutes played'] >= high_threshold, 1.0,
                np.where(df_clean['Minutes played'] >= med_threshold, 0.7,
                        np.where(df_clean['Minutes played'] >= min_threshold, 0.4, 0.2))
            )
            
            # Factor de participaci√≥n relativa
            if 'Matches played' in df_clean.columns:
                df_clean['participation_ratio'] = np.where(
                    df_clean['Matches played'] > 0,
                    df_clean['Minutes played'] / (df_clean['Matches played'] * 90),
                    0
                ).clip(0, 1)
            else:
                df_clean['participation_ratio'] = 0.5  # Valor neutro si no hay datos
            
            # Score de confianza final
            df_clean['confidence_score'] = (
                df_clean['minutes_score'] * 0.6 + 
                df_clean['participation_ratio'] * 0.4
            ) * 100
            
            # Categor√≠as de calidad
            df_clean['data_quality'] = pd.cut(
                df_clean['confidence_score'], 
                bins=[0, 30, 60, 100],
                labels=['low', 'medium', 'high'],
                include_lowest=True
            )
            
            print(f"üìä DISTRIBUCI√ìN POR CALIDAD DE DATOS:")
            quality_dist = df_clean['data_quality'].value_counts()
            for quality, count in quality_dist.items():
                pct = (count / len(df_clean)) * 100
                print(f"   {quality}: {count:,} registros ({pct:.1f}%)")
        
        # Todos los registros se consideran "v√°lidos" pero con calidad marcada
        df_valid = df_clean.copy()
        
        # Estad√≠sticas de validaci√≥n
        total_records = len(df)
        valid_records = len(df_valid)
        valid_percentage = (valid_records / total_records) * 100 if total_records > 0 else 0
        
        # Temporadas
        seasons = sorted(df['season'].unique())
        
        # Posiciones
        if 'Primary position' in df.columns:
            positions = df['Primary position'].dropna().unique()
        else:
            positions = []
        
        # Equipos
        if 'Team' in df.columns:
            teams = df['Team'].dropna().unique()
            n_teams = len(teams)
        else:
            n_teams = 0
        
        validation_results = {
            'total_records': total_records,
            'valid_records': valid_records,
            'valid_percentage': valid_percentage,
            'n_seasons': len(seasons),
            'seasons': seasons,
            'n_positions': len(positions),
            'positions': positions[:10] if len(positions) > 10 else positions,  # Mostrar max 10
            'n_teams': n_teams,
            'data_quality': 'Excelente' if valid_records > 1000 else 'Buena' if valid_records > 500 else 'Limitada',
            'dataframe': df_valid
        }
        
        # Imprimir resumen
        print(f"üìä Registros totales: {total_records:,}")
        print(f"‚úÖ Registros procesados: {valid_records:,} ({valid_percentage:.1f}%)")
        
        # Mostrar estad√≠sticas por calidad si disponible
        if 'data_quality' in df_valid.columns:
            high_quality = len(df_valid[df_valid['data_quality'] == 'high'])
            medium_quality = len(df_valid[df_valid['data_quality'] == 'medium']) 
            low_quality = len(df_valid[df_valid['data_quality'] == 'low'])
            
            print(f"üü¢ Alta calidad: {high_quality:,} ({high_quality/len(df_valid)*100:.1f}%)")
            print(f"üü° Calidad media: {medium_quality:,} ({medium_quality/len(df_valid)*100:.1f}%)")
            print(f"üî¥ Baja calidad: {low_quality:,} ({low_quality/len(df_valid)*100:.1f}%)")
        print(f"üìÖ Temporadas: {len(seasons)} ({', '.join(seasons)})")
        print(f"‚öΩ Posiciones: {len(positions)} (mostrando primeras 10: {', '.join(map(str, positions[:10]))})")
        print(f"üèüÔ∏è Equipos: {n_teams}")
        print(f"üéØ Calidad de datos: {validation_results['data_quality']}")
        
        if valid_records < 500:
            print("\n‚ö†Ô∏è ADVERTENCIA: Pocos datos para an√°lisis robusto")
            print("   Recomendaci√≥n: Considerar incluir datos de segunda divisi√≥n")
        else:
            print("\n‚úÖ Validaci√≥n exitosa - Datos suficientes para an√°lisis acad√©mico")
        
        return validation_results
        
    except Exception as e:
        print(f"‚ùå Error en validaci√≥n de calidad: {e}")
        return None


def run_basic_eda_analysis(df: pd.DataFrame) -> Optional[pd.DataFrame]:
    """
    Ejecuta an√°lisis exploratorio b√°sico sobre DataFrame de CSV.
    
    Args:
        df: DataFrame con datos cargados de CSV
        
    Returns:
        DataFrame con datos v√°lidos o None si falla
    """
    try:
        print_header("üìä AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)", "=", 70)
        
        print(f"‚úÖ Datos cargados: {len(df)} registros, {len(df.columns)} columnas")
        
        # Estad√≠sticas b√°sicas
        print(f"\nüìà ESTAD√çSTICAS B√ÅSICAS:")
        
        # Informaci√≥n de temporadas
        if 'season' in df.columns:
            season_counts = df['season'].value_counts().sort_index()
            print(f"   üìÖ Distribuci√≥n temporal:")
            for season, count in season_counts.items():
                if pd.notna(season):
                    print(f"      {season}: {count:,} registros")
        
        # Informaci√≥n de posiciones
        if 'Primary position' in df.columns:
            position_counts = df['Primary position'].value_counts()
            print(f"\n   ‚öΩ Distribuci√≥n por posiciones:")
            for position, count in position_counts.head(8).items():
                if pd.notna(position):
                    pct = (count / len(df)) * 100
                    print(f"      {position}: {count:,} ({pct:.1f}%)")
        
        # An√°lisis de completitud de variables clave (nombres CSV)
        key_variables = [
            'Goals', 'Assists', 'Matches played', 'Minutes played',
            'Pass accuracy, %', 'Duels won, %', 'Goals per 90', 'Assists per 90'
        ]
        
        available_vars = [var for var in key_variables if var in df.columns]
        
        print(f"\n   üîç Completitud de variables clave:")
        for var in available_vars:
            completeness = (df[var].notna().sum() / len(df)) * 100
            print(f"      {var}: {completeness:.1f}% completo")
        
        # Estad√≠sticas de variables num√©ricas principales
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        key_numeric = [col for col in ['Goals', 'Assists', 'Matches played', 'Age'] if col in numeric_cols]
        
        if key_numeric:
            print(f"\n   üìä Estad√≠sticas descriptivas:")
            desc_stats = df[key_numeric].describe()
            print(desc_stats.round(2))
        
        # Filtrar datos v√°lidos para an√°lisis posterior
        valid_mask = pd.Series([True] * len(df), index=df.index)
        
        if 'Minutes played' in df.columns:
            valid_mask = valid_mask & (df['Minutes played'].fillna(0) >= 180)
        
        if 'Primary position' in df.columns:
            valid_mask = valid_mask & (df['Primary position'].notna())
        
        df_valid = df[valid_mask].copy()
        
        print(f"\n‚úÖ Datos v√°lidos para modelado: {len(df_valid)} registros ({len(df_valid)/len(df)*100:.1f}%)")
        
        return df_valid
        
    except Exception as e:
        logger.error(f"Error en EDA b√°sico: {e}")
        print(f"‚ùå Error en an√°lisis exploratorio: {e}")
        return None


def create_position_analysis_visualization(df: pd.DataFrame) -> None:
    """
    Crea visualizaci√≥n acad√©mica de an√°lisis por posiciones usando columnas CSV.
    
    Args:
        df: DataFrame con datos de jugadores de CSV
    """
    try:
        print("\nüé® Generando visualizaci√≥n por posiciones...")
        
        position_col = 'Primary position'
        if position_col not in df.columns:
            print("‚ö†Ô∏è No hay informaci√≥n de posiciones para visualizar")
            return
        
        # Preparar datos por posici√≥n
        position_data = df[df[position_col].notna()].copy()
        
        if len(position_data) == 0:
            print("‚ö†Ô∏è No hay datos v√°lidos por posici√≥n")
            return
        
        # Crear visualizaci√≥n multi-panel
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=[
                "Distribuci√≥n por Posici√≥n",
                "Minutos Jugados por Posici√≥n", 
                "Goles y Asistencias por Posici√≥n",
                "Edad por Posici√≥n"
            ],
            specs=[[{"type": "pie"}, {"type": "box"}],
                   [{"type": "scatter"}, {"type": "violin"}]]
        )
        
        # 1. Pie chart de distribuci√≥n
        position_counts = position_data[position_col].value_counts()
        
        fig.add_trace(
            go.Pie(
                labels=position_counts.index,
                values=position_counts.values,
                hole=0.3,
                showlegend=True
            ),
            row=1, col=1
        )
        
        # 2. Box plot de minutos por posici√≥n
        minutes_col = 'Minutes played'
        if minutes_col in df.columns:
            positions = position_counts.index[:8]  # Top 8 posiciones
            
            for i, position in enumerate(positions):
                pos_data = position_data[position_data[position_col] == position]
                minutes = pos_data[minutes_col].dropna()
                
                if len(minutes) > 0:
                    fig.add_trace(
                        go.Box(
                            y=minutes,
                            name=position,
                            showlegend=False,
                            marker_color=px.colors.qualitative.Set1[i % len(px.colors.qualitative.Set1)]
                        ),
                        row=1, col=2
                    )
        
        # 3. Scatter de goles vs asistencias por posici√≥n
        goals_col = 'Goals'
        assists_col = 'Assists'
        if goals_col in df.columns and assists_col in df.columns:
            for i, position in enumerate(positions):
                pos_data = position_data[position_data[position_col] == position]
                
                valid_data = pos_data[[goals_col, assists_col]].dropna()
                if len(valid_data) > 0:
                    fig.add_trace(
                        go.Scatter(
                            x=valid_data[goals_col],
                            y=valid_data[assists_col],
                            mode='markers',
                            name=position,
                            showlegend=False,
                            marker=dict(
                                color=px.colors.qualitative.Set1[i % len(px.colors.qualitative.Set1)],
                                size=6,
                                opacity=0.7
                            )
                        ),
                        row=2, col=1
                    )
        
        # 4. Violin plot de edad por posici√≥n
        age_col = 'Age'
        if age_col in df.columns:
            for i, position in enumerate(positions):
                pos_data = position_data[position_data[position_col] == position]
                ages = pos_data[age_col].dropna()
                
                if len(ages) > 5:  # M√≠nimo 5 jugadores para violin plot
                    fig.add_trace(
                        go.Violin(
                            y=ages,
                            name=position,
                            showlegend=False,
                            meanline_visible=True
                        ),
                        row=2, col=2
                    )
        
        # Layout acad√©mico
        fig.update_layout(
            height=800,
            title_text="üìä An√°lisis Integral por Posiciones - Liga Tailandesa",
            title_x=0.5,
            font=dict(family="Arial", size=12)
        )
        
        # Etiquetas
        fig.update_yaxes(title_text="Minutos Jugados", row=1, col=2)
        fig.update_xaxes(title_text="Goles", row=2, col=1)
        fig.update_yaxes(title_text="Asistencias", row=2, col=1)
        fig.update_yaxes(title_text="Edad (a√±os)", row=2, col=2)
        
        # Guardar visualizaci√≥n en lugar de mostrarla interactivamente
        try:
            fig.write_html('visualizations/position_analysis.html')
            print("‚úÖ Visualizaci√≥n guardada en: visualizations/position_analysis.html")
        except:
            print("‚ÑπÔ∏è Visualizaci√≥n generada (no guardada - directorio no existe)")
            # fig.show()  # Comentado para evitar bloqueo
        
    except Exception as e:
        logger.error(f"Error generando visualizaci√≥n: {e}")
        print(f"‚ö†Ô∏è Error en visualizaci√≥n: {e}")


def run_baseline_model_evaluation(df_valid: pd.DataFrame) -> Optional[Dict]:
    """
    Ejecuta evaluaci√≥n completa de modelos baseline.
    
    Args:
        df_valid: DataFrame con datos v√°lidos
        
    Returns:
        Diccionario con resultados de evaluaci√≥n
    """
    try:
        print_header("ü§ñ EVALUACI√ìN DE MODELOS BASELINE", "=", 70)
        
        # Preparar features usando el baseline model
        print("üîß Preparando features baseline...")
        
        baseline_model = LinearBaselineModel()
        X_df = baseline_model.extract_baseline_features(df_valid)
        y = baseline_model.calculate_target_pdi(df_valid)
        
        print(f"‚úÖ Features preparadas: {X_df.shape}")
        print(f"üìà Target PDI - Media: {np.mean(y):.1f}, Std: {np.std(y):.1f}")
        
        # Convertir a arrays numpy
        X = X_df.values
        feature_names = X_df.columns.tolist()
        
        # Extraer posiciones usando la columna correcta
        if 'primary_position' in df_valid.columns:
            positions = df_valid['primary_position'].values
        elif 'Primary position' in df_valid.columns:
            positions = df_valid['Primary position'].values
        else:
            positions = np.array(['Unknown'] * len(df_valid))
        
        # Configurar pipeline de evaluaci√≥n
        eval_config = {
            'cv_folds': 5,
            'primary_metric': 'mae',
            'position_analysis': True,
            'save_results': True,
            'results_dir': 'results/baseline_evaluation'
        }
        
        pipeline = create_evaluation_pipeline(eval_config)
        
        # Crear modelos baseline
        models = {
            'Linear Baseline': LinearBaselineModel(),
            'Ridge Baseline': RidgeBaselineModel(alpha=1.0),
            'Ridge Strong': RidgeBaselineModel(alpha=10.0),
            'Ensemble Baseline': EnsembleBaselineModel(n_estimators=50)
        }
        
        print(f"üöÄ Evaluando {len(models)} modelos baseline...")
        
        # Evaluar modelos
        results = pipeline.evaluate_multiple_models(
            models=models,
            X=X,
            y=y,
            positions=positions,
            feature_names=feature_names
        )
        
        # Generar reporte acad√©mico
        print("\nüìã Generando reporte acad√©mico...")
        academic_report = pipeline.generate_academic_report(results)
        print(academic_report)
        
        # Guardar reporte
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = f"baseline_evaluation_report_{timestamp}.txt"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(academic_report)
            print(f"üìÅ Reporte guardado en: {report_path}")
        except Exception as e:
            logger.warning(f"No se pudo guardar reporte: {e}")
        
        # Resumen ejecutivo para consola
        best_model = min(results.items(), key=lambda x: x[1].mae)
        
        print_header("üéØ RESUMEN EJECUTIVO", "-", 60)
        print(f"üèÜ Mejor modelo: {best_model[0]}")
        print(f"üìä MAE: {best_model[1].mae:.3f} ¬± {best_model[1].cv_std.get('mae', 0):.3f}")
        print(f"üìä R¬≤: {best_model[1].r2:.3f}")
        print(f"üìä MAPE: {best_model[1].mape:.1f}%")
        
        # Evaluaci√≥n del objetivo acad√©mico
        target_mae = 15.0
        meets_target = best_model[1].mae < target_mae
        
        print(f"\nüéØ OBJETIVO ACAD√âMICO (MAE < {target_mae}):")
        if meets_target:
            print(f"   ‚úÖ CUMPLIDO - MAE = {best_model[1].mae:.3f}")
            print("   üöÄ Baseline s√≥lido establecido para modelos avanzados")
        else:
            gap = best_model[1].mae - target_mae
            print(f"   ‚ùå NO CUMPLIDO - Gap: {gap:.3f} puntos")
            print("   üí° Considerar features adicionales o modelos m√°s complejos")
        
        return {
            'results': results,
            'best_model': best_model,
            'meets_target': meets_target,
            'evaluation_pipeline': pipeline
        }
        
    except Exception as e:
        logger.error(f"Error en evaluaci√≥n baseline: {e}")
        print(f"‚ùå Error en evaluaci√≥n de modelos: {e}")
        return None


def print_final_recommendations(evaluation_results: Dict) -> None:
    """
    Imprime recomendaciones finales acad√©micas.
    
    Args:
        evaluation_results: Resultados de la evaluaci√≥n
    """
    print_header("üí° RECOMENDACIONES ACAD√âMICAS FINALES", "=", 70)
    
    if evaluation_results is None:
        print("‚ùå No hay resultados para generar recomendaciones")
        return
    
    best_model_name, best_performance = evaluation_results['best_model']
    meets_target = evaluation_results['meets_target']
    
    print(f"üìä AN√ÅLISIS DE RESULTADOS:")
    print(f"   ‚Ä¢ Mejor modelo identificado: {best_model_name}")
    print(f"   ‚Ä¢ MAE logrado: {best_performance.mae:.3f}")
    print(f"   ‚Ä¢ Estabilidad CV: {1 - (best_performance.cv_std.get('mae', 0) / best_performance.cv_mean.get('mae', 1)):.3f}")
    
    print(f"\nüöÄ PR√ìXIMOS PASOS METODOL√ìGICOS:")
    
    if meets_target:
        print("‚úÖ FASE 1 COMPLETADA - Baseline s√≥lido establecido")
        print("\nüéØ RECOMENDACIONES PARA FASE 2:")
        print("   1. Implementar modelos avanzados (Random Forest, Gradient Boosting)")
        print("   2. Optimizar hiperpar√°metros usando Grid Search")
        print("   3. Explorar feature engineering avanzado")
        print("   4. Implementar ensemble methods")
        print("   5. Validar con datos de temporadas futuras")
    else:
        print("‚ö†Ô∏è BASELINE REQUIERE MEJORA")
        print("\nüîß RECOMENDACIONES DE MEJORA:")
        print("   1. Revisar y ampliar conjunto de features")
        print("   2. Implementar imputaci√≥n avanzada de valores faltantes")
        print("   3. Considerar transformaciones de features (log, sqrt)")
        print("   4. Evaluar modelos no lineales desde baseline")
        print("   5. An√°lizar outliers e instances dif√≠ciles")
    
    print(f"\nüìà CONTRIBUCI√ìN ACAD√âMICA:")
    print("   ‚Ä¢ Framework de evaluaci√≥n riguroso establecido")
    print("   ‚Ä¢ Metodolog√≠a CRISP-DM implementada correctamente")
    print("   ‚Ä¢ Baseline reproducible para investigaci√≥n futura")
    print("   ‚Ä¢ An√°lisis estad√≠stico con significancia validada")
    
    print(f"\nüìö VALIDEZ CIENT√çFICA:")
    print("   ‚Ä¢ Validaci√≥n cruzada estratificada implementada")
    print("   ‚Ä¢ Intervalos de confianza calculados")
    print("   ‚Ä¢ Tests estad√≠sticos de significancia aplicados")
    print("   ‚Ä¢ Metodolog√≠a reproducible documentada")
    
    print(f"\nüéì CONCLUSIONES PARA MEMORIA DE M√ÅSTER:")
    print("   1. Dataset de Liga Tailandesa es robusto para investigaci√≥n PDI")
    print("   2. Modelos baseline proporcionan fundaci√≥n s√≥lida")
    print("   3. Framework desarrollado es escalable y reproducible")
    print("   4. An√°lisis por posici√≥n revela patrones espec√≠ficos")
    print("   5. Metodolog√≠a cumple est√°ndares acad√©micos internacionales")


def main():
    """Funci√≥n principal que ejecuta todo el pipeline acad√©mico."""
    
    # Header principal
    print_header("üéì AN√ÅLISIS ACAD√âMICO PDI - LIGA TAILANDESA", "=", 80)
    print("Proyecto: Player Development Index (PDI) usando Machine Learning")
    print("Metodolog√≠a: CRISP-DM con rigor acad√©mico")
    print("Objetivo: Establecer baseline s√≥lido para predicci√≥n PDI")
    print("Dataset: Liga Tailandesa (5 temporadas)")
    print(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    try:
        # Fase 1: Cargar datos desde CSV
        combined_df = load_thai_league_csv_data()
        if combined_df is None:
            print("‚ùå Carga de CSV fall√≥ - Terminando ejecuci√≥n")
            return
        
        # Fase 2: Validaci√≥n de calidad
        validation_results = validate_data_quality(combined_df)
        if validation_results is None:
            print("‚ùå Validaci√≥n de calidad fall√≥ - Terminando ejecuci√≥n")
            return
            
        df_valid = validation_results['dataframe']
        
        # Fase 3: An√°lisis exploratorio
        df_eda = run_basic_eda_analysis(df_valid)
        if df_eda is None or len(df_eda) < 100:
            print("‚ùå EDA fall√≥ o datos insuficientes - Terminando ejecuci√≥n")
            return
        
        df_valid = df_eda  # Usar datos procesados por EDA
        
        # Fase 4: Visualizaci√≥n por posiciones
        create_position_analysis_visualization(df_valid)
        
        # Fase 5: Evaluaci√≥n de modelos baseline
        evaluation_results = run_baseline_model_evaluation(df_valid)
        
        # Fase 6: Recomendaciones finales
        print_final_recommendations(evaluation_results)
        
        # Finalizaci√≥n exitosa
        print_header("‚úÖ AN√ÅLISIS COMPLETADO EXITOSAMENTE", "=", 70)
        print("üéâ Pipeline acad√©mico ejecutado completo")
        print("üìä Resultados disponibles para an√°lisis posterior")
        print("üìÅ Archivos generados:")
        print("   ‚Ä¢ Log de ejecuci√≥n")
        print("   ‚Ä¢ Reporte acad√©mico detallado")
        print("   ‚Ä¢ Resultados de evaluaci√≥n (CSV/JSON)")
        print("   ‚Ä¢ Visualizaciones interactivas")
        
        print(f"\nüöÄ PR√ìXIMOS PASOS:")
        print("1. Revisar notebook EDA completo: notebooks/01_EDA_Liga_Tailandesa.ipynb")
        print("2. Analizar resultados detallados en results/baseline_evaluation/")
        print("3. Implementar modelos avanzados basados en estos resultados")
        print("4. Documentar metodolog√≠a en memoria de m√°ster")
        
        print("\nüéì CONTRIBUCI√ìN ACAD√âMICA ESTABLECIDA")
        print("="*70)
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Ejecuci√≥n interrumpida por el usuario")
        logger.info("Ejecuci√≥n interrumpida por el usuario")
    except Exception as e:
        logger.error(f"Error cr√≠tico en ejecuci√≥n principal: {e}")
        print(f"\n‚ùå ERROR CR√çTICO: {e}")
        print("üîß Revisar logs para detalles t√©cnicos")
        print("üí° Contactar soporte t√©cnico si el problema persiste")
    finally:
        print(f"\nüìù Log completo disponible en: eda_baseline_analysis_{datetime.now().strftime('%Y%m%d')}.log")


if __name__ == "__main__":
    main()