#!/usr/bin/env python3
"""
Script Principal - AnÃ¡lisis EDA + Modelo Baseline PDI Liga Tailandesa

Este script ejecuta el pipeline completo de anÃ¡lisis exploratorio y evaluaciÃ³n
de modelos baseline para el Player Development Index (PDI) siguiendo metodologÃ­a
CRISP-DM con rigor acadÃ©mico.

Fases implementadas:
1. AnÃ¡lisis Exploratorio de Datos (EDA)
2. PreparaciÃ³n de features baseline
3. Entrenamiento y evaluaciÃ³n de modelos baseline
4. AnÃ¡lisis estadÃ­stico comparativo
5. GeneraciÃ³n de reportes acadÃ©micos

Objetivo acadÃ©mico: Establecer baseline sÃ³lido con MAE < 15 para futuros modelos.

Autor: Proyecto Fin de MÃ¡ster - Python Aplicado al Deporte
Fecha: Agosto 2025
Dataset: Liga Tailandesa (2,359 registros, 155 variables)
"""

import sys
import os
import logging
import warnings
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional

# Configurar path del proyecto
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# Importaciones del proyecto
try:
    from controllers.ml.baseline_model import (
        LinearBaselineModel, RidgeBaselineModel, EnsembleBaselineModel,
        run_comprehensive_baseline_evaluation
    )
    from controllers.ml.evaluation_pipeline import (
        create_evaluation_pipeline, EvaluationConfig
    )
except ImportError as e:
    print(f"âŒ Error importando mÃ³dulos del proyecto: {e}")
    print("ğŸ”§ AsegÃºrate de estar en el directorio correcto del proyecto")
    sys.exit(1)

# LibrerÃ­as externas
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(f'eda_baseline_analysis_{datetime.now().strftime("%Y%m%d")}.log')
    ]
)
logger = logging.getLogger(__name__)

# Suprimir warnings para output mÃ¡s limpio
warnings.filterwarnings('ignore')


def print_header(title: str, char: str = "=", width: int = 80) -> None:
    """Imprime header acadÃ©mico formateado."""
    print("\n" + char * width)
    print(f"{title:^{width}}")
    print(char * width)


def load_thai_league_csv_data() -> Optional[pd.DataFrame]:
    """
    Carga todos los CSV de Thai League desde data/thai_league_cache/.
    
    Returns:
        DataFrame combinado con todos los datos o None si falla
    """
    try:
        print_header("ğŸ” CARGANDO DATOS CSV THAI LEAGUE", "=", 60)
        
        csv_dir = Path('data/thai_league_cache')
        if not csv_dir.exists():
            print(f"âŒ Directorio no encontrado: {csv_dir}")
            return None
        
        csv_files = list(csv_dir.glob('thai_league_*.csv'))
        if not csv_files:
            print(f"âŒ No se encontraron archivos CSV en: {csv_dir}")
            return None
        
        print(f"ğŸ“ Archivos CSV encontrados: {len(csv_files)}")
        
        all_dataframes = []
        total_records = 0
        
        for csv_file in sorted(csv_files):
            try:
                season = csv_file.stem.replace('thai_league_', '')
                df = pd.read_csv(csv_file)
                df['season'] = season  # Agregar columna de temporada
                
                print(f"   ğŸ“Š {season}: {len(df):,} registros, {len(df.columns)} columnas")
                all_dataframes.append(df)
                total_records += len(df)
                
            except Exception as e:
                print(f"   âŒ Error cargando {csv_file}: {e}")
                continue
        
        if not all_dataframes:
            print("âŒ No se pudo cargar ningÃºn archivo CSV")
            return None
        
        # Combinar todos los DataFrames
        combined_df = pd.concat(all_dataframes, ignore_index=True)
        
        print(f"\nâœ… DATOS COMBINADOS:")
        print(f"   ğŸ“Š Total registros: {len(combined_df):,}")
        print(f"   ğŸ“Š Total columnas: {len(combined_df.columns)}")
        print(f"   ğŸ“… Temporadas: {len(combined_df['season'].unique())}")
        
        # Mostrar distribuciÃ³n por temporada
        season_counts = combined_df['season'].value_counts().sort_index()
        print(f"\nğŸ“ˆ DISTRIBUCIÃ“N POR TEMPORADA:")
        for season, count in season_counts.items():
            print(f"   {season}: {count:,} registros")
        
        return combined_df
        
    except Exception as e:
        print(f"âŒ Error cargando datos CSV: {e}")
        return None


def validate_data_quality(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Valida la calidad de los datos cargados desde CSV usando filtros inteligentes.
    
    Args:
        df: DataFrame con datos de Thai League
        
    Returns:
        Dict con estadÃ­sticas de validaciÃ³n y DataFrame mejorado
    """
    try:
        print_header("ğŸ” VALIDACIÃ“N INTELIGENTE DE DATOS", "=", 60)
        
        # FILTROS DUROS (eliminaciÃ³n): solo registros claramente invÃ¡lidos
        hard_filters = pd.Series([True] * len(df), index=df.index)
        
        if 'Primary position' in df.columns:
            hard_filters = hard_filters & (df['Primary position'].notna())
            
        if 'Minutes played' in df.columns:
            hard_filters = hard_filters & (df['Minutes played'].fillna(0) > 0)
            
        if 'Player' in df.columns:
            hard_filters = hard_filters & (df['Player'].notna())
        
        df_clean = df[hard_filters].copy()
        eliminated = len(df) - len(df_clean)
        print(f"ğŸš« Registros eliminados (invÃ¡lidos): {eliminated}")
        
        # SISTEMA DE CONFIANZA: mantener todos pero marcar calidad
        if 'Minutes played' in df_clean.columns:
            # Threshold flexible basado en percentiles
            min_threshold = max(90, df_clean['Minutes played'].quantile(0.05))  # MÃ­nimo 1 partido o 5% percentil
            med_threshold = df_clean['Minutes played'].quantile(0.30)  # 30% percentil
            high_threshold = df_clean['Minutes played'].quantile(0.60)  # 60% percentil
            
            # Score de confianza basado en mÃºltiples factores
            df_clean['minutes_score'] = np.where(
                df_clean['Minutes played'] >= high_threshold, 1.0,
                np.where(df_clean['Minutes played'] >= med_threshold, 0.7,
                        np.where(df_clean['Minutes played'] >= min_threshold, 0.4, 0.2))
            )
            
            # Factor de participaciÃ³n relativa
            if 'Matches played' in df_clean.columns:
                df_clean['participation_ratio'] = np.where(
                    df_clean['Matches played'] > 0,
                    df_clean['Minutes played'] / (df_clean['Matches played'] * 90),
                    0
                ).clip(0, 1)
            else:
                df_clean['participation_ratio'] = 0.5  # Valor neutro si no hay datos
            
            # Score de confianza final
            df_clean['confidence_score'] = (
                df_clean['minutes_score'] * 0.6 + 
                df_clean['participation_ratio'] * 0.4
            ) * 100
            
            # CategorÃ­as de calidad
            df_clean['data_quality'] = pd.cut(
                df_clean['confidence_score'], 
                bins=[0, 30, 60, 100],
                labels=['low', 'medium', 'high'],
                include_lowest=True
            )
            
            print(f"ğŸ“Š DISTRIBUCIÃ“N POR CALIDAD DE DATOS:")
            quality_dist = df_clean['data_quality'].value_counts()
            for quality, count in quality_dist.items():
                pct = (count / len(df_clean)) * 100
                print(f"   {quality}: {count:,} registros ({pct:.1f}%)")
        
        # Todos los registros se consideran "vÃ¡lidos" pero con calidad marcada
        df_valid = df_clean.copy()
        
        # EstadÃ­sticas de validaciÃ³n
        total_records = len(df)
        valid_records = len(df_valid)
        valid_percentage = (valid_records / total_records) * 100 if total_records > 0 else 0
        
        # Temporadas
        seasons = sorted(df['season'].unique())
        
        # Posiciones
        if 'Primary position' in df.columns:
            positions = df['Primary position'].dropna().unique()
        else:
            positions = []
        
        # Equipos
        if 'Team' in df.columns:
            teams = df['Team'].dropna().unique()
            n_teams = len(teams)
        else:
            n_teams = 0
        
        validation_results = {
            'total_records': total_records,
            'valid_records': valid_records,
            'valid_percentage': valid_percentage,
            'n_seasons': len(seasons),
            'seasons': seasons,
            'n_positions': len(positions),
            'positions': positions[:10] if len(positions) > 10 else positions,  # Mostrar max 10
            'n_teams': n_teams,
            'data_quality': 'Excelente' if valid_records > 1000 else 'Buena' if valid_records > 500 else 'Limitada',
            'dataframe': df_valid
        }
        
        # Imprimir resumen
        print(f"ğŸ“Š Registros totales: {total_records:,}")
        print(f"âœ… Registros procesados: {valid_records:,} ({valid_percentage:.1f}%)")
        
        # Mostrar estadÃ­sticas por calidad si disponible
        if 'data_quality' in df_valid.columns:
            high_quality = len(df_valid[df_valid['data_quality'] == 'high'])
            medium_quality = len(df_valid[df_valid['data_quality'] == 'medium']) 
            low_quality = len(df_valid[df_valid['data_quality'] == 'low'])
            
            print(f"ğŸŸ¢ Alta calidad: {high_quality:,} ({high_quality/len(df_valid)*100:.1f}%)")
            print(f"ğŸŸ¡ Calidad media: {medium_quality:,} ({medium_quality/len(df_valid)*100:.1f}%)")
            print(f"ğŸ”´ Baja calidad: {low_quality:,} ({low_quality/len(df_valid)*100:.1f}%)")
        print(f"ğŸ“… Temporadas: {len(seasons)} ({', '.join(seasons)})")
        print(f"âš½ Posiciones: {len(positions)} (mostrando primeras 10: {', '.join(map(str, positions[:10]))})")
        print(f"ğŸŸï¸ Equipos: {n_teams}")
        print(f"ğŸ¯ Calidad de datos: {validation_results['data_quality']}")
        
        if valid_records < 500:
            print("\nâš ï¸ ADVERTENCIA: Pocos datos para anÃ¡lisis robusto")
            print("   RecomendaciÃ³n: Considerar incluir datos de segunda divisiÃ³n")
        else:
            print("\nâœ… ValidaciÃ³n exitosa - Datos suficientes para anÃ¡lisis acadÃ©mico")
        
        return validation_results
        
    except Exception as e:
        print(f"âŒ Error en validaciÃ³n de calidad: {e}")
        return None


def run_basic_eda_analysis(df: pd.DataFrame) -> Optional[pd.DataFrame]:
    """
    Ejecuta anÃ¡lisis exploratorio bÃ¡sico sobre DataFrame de CSV.
    
    Args:
        df: DataFrame con datos cargados de CSV
        
    Returns:
        DataFrame con datos vÃ¡lidos o None si falla
    """
    try:
        print_header("ğŸ“Š ANÃLISIS EXPLORATORIO DE DATOS (EDA)", "=", 70)
        
        print(f"âœ… Datos cargados: {len(df)} registros, {len(df.columns)} columnas")
        
        # EstadÃ­sticas bÃ¡sicas
        print(f"\nğŸ“ˆ ESTADÃSTICAS BÃSICAS:")
        
        # InformaciÃ³n de temporadas
        if 'season' in df.columns:
            season_counts = df['season'].value_counts().sort_index()
            print(f"   ğŸ“… DistribuciÃ³n temporal:")
            for season, count in season_counts.items():
                if pd.notna(season):
                    print(f"      {season}: {count:,} registros")
        
        # InformaciÃ³n de posiciones
        if 'Primary position' in df.columns:
            position_counts = df['Primary position'].value_counts()
            print(f"\n   âš½ DistribuciÃ³n por posiciones:")
            for position, count in position_counts.head(8).items():
                if pd.notna(position):
                    pct = (count / len(df)) * 100
                    print(f"      {position}: {count:,} ({pct:.1f}%)")
        
        # AnÃ¡lisis de completitud de variables clave (nombres CSV)
        key_variables = [
            'Goals', 'Assists', 'Matches played', 'Minutes played',
            'Pass accuracy, %', 'Duels won, %', 'Goals per 90', 'Assists per 90'
        ]
        
        available_vars = [var for var in key_variables if var in df.columns]
        
        print(f"\n   ğŸ” Completitud de variables clave:")
        for var in available_vars:
            completeness = (df[var].notna().sum() / len(df)) * 100
            print(f"      {var}: {completeness:.1f}% completo")
        
        # EstadÃ­sticas de variables numÃ©ricas principales
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        key_numeric = [col for col in ['Goals', 'Assists', 'Matches played', 'Age'] if col in numeric_cols]
        
        if key_numeric:
            print(f"\n   ğŸ“Š EstadÃ­sticas descriptivas:")
            desc_stats = df[key_numeric].describe()
            print(desc_stats.round(2))
        
        # Filtrar datos vÃ¡lidos para anÃ¡lisis posterior
        valid_mask = pd.Series([True] * len(df), index=df.index)
        
        if 'Minutes played' in df.columns:
            valid_mask = valid_mask & (df['Minutes played'].fillna(0) >= 180)
        
        if 'Primary position' in df.columns:
            valid_mask = valid_mask & (df['Primary position'].notna())
        
        df_valid = df[valid_mask].copy()
        
        print(f"\nâœ… Datos vÃ¡lidos para modelado: {len(df_valid)} registros ({len(df_valid)/len(df)*100:.1f}%)")
        
        return df_valid
        
    except Exception as e:
        logger.error(f"Error en EDA bÃ¡sico: {e}")
        print(f"âŒ Error en anÃ¡lisis exploratorio: {e}")
        return None


def create_position_analysis_visualization(df: pd.DataFrame) -> None:
    """
    Crea visualizaciÃ³n acadÃ©mica de anÃ¡lisis por posiciones usando columnas CSV.
    
    Args:
        df: DataFrame con datos de jugadores de CSV
    """
    try:
        print("\nğŸ¨ Generando visualizaciÃ³n por posiciones...")
        
        position_col = 'Primary position'
        if position_col not in df.columns:
            print("âš ï¸ No hay informaciÃ³n de posiciones para visualizar")
            return
        
        # Preparar datos por posiciÃ³n
        position_data = df[df[position_col].notna()].copy()
        
        if len(position_data) == 0:
            print("âš ï¸ No hay datos vÃ¡lidos por posiciÃ³n")
            return
        
        # Crear visualizaciÃ³n multi-panel
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=[
                "DistribuciÃ³n por PosiciÃ³n",
                "Minutos Jugados por PosiciÃ³n", 
                "Goles y Asistencias por PosiciÃ³n",
                "Edad por PosiciÃ³n"
            ],
            specs=[[{"type": "pie"}, {"type": "box"}],
                   [{"type": "scatter"}, {"type": "violin"}]]
        )
        
        # 1. Pie chart de distribuciÃ³n
        position_counts = position_data[position_col].value_counts()
        
        fig.add_trace(
            go.Pie(
                labels=position_counts.index,
                values=position_counts.values,
                hole=0.3,
                showlegend=True
            ),
            row=1, col=1
        )
        
        # 2. Box plot de minutos por posiciÃ³n
        minutes_col = 'Minutes played'
        if minutes_col in df.columns:
            positions = position_counts.index[:8]  # Top 8 posiciones
            
            for i, position in enumerate(positions):
                pos_data = position_data[position_data[position_col] == position]
                minutes = pos_data[minutes_col].dropna()
                
                if len(minutes) > 0:
                    fig.add_trace(
                        go.Box(
                            y=minutes,
                            name=position,
                            showlegend=False,
                            marker_color=px.colors.qualitative.Set1[i % len(px.colors.qualitative.Set1)]
                        ),
                        row=1, col=2
                    )
        
        # 3. Scatter de goles vs asistencias por posiciÃ³n
        goals_col = 'Goals'
        assists_col = 'Assists'
        if goals_col in df.columns and assists_col in df.columns:
            for i, position in enumerate(positions):
                pos_data = position_data[position_data[position_col] == position]
                
                valid_data = pos_data[[goals_col, assists_col]].dropna()
                if len(valid_data) > 0:
                    fig.add_trace(
                        go.Scatter(
                            x=valid_data[goals_col],
                            y=valid_data[assists_col],
                            mode='markers',
                            name=position,
                            showlegend=False,
                            marker=dict(
                                color=px.colors.qualitative.Set1[i % len(px.colors.qualitative.Set1)],
                                size=6,
                                opacity=0.7
                            )
                        ),
                        row=2, col=1
                    )
        
        # 4. Violin plot de edad por posiciÃ³n
        age_col = 'Age'
        if age_col in df.columns:
            for i, position in enumerate(positions):
                pos_data = position_data[position_data[position_col] == position]
                ages = pos_data[age_col].dropna()
                
                if len(ages) > 5:  # MÃ­nimo 5 jugadores para violin plot
                    fig.add_trace(
                        go.Violin(
                            y=ages,
                            name=position,
                            showlegend=False,
                            meanline_visible=True
                        ),
                        row=2, col=2
                    )
        
        # Layout acadÃ©mico
        fig.update_layout(
            height=800,
            title_text="ğŸ“Š AnÃ¡lisis Integral por Posiciones - Liga Tailandesa",
            title_x=0.5,
            font=dict(family="Arial", size=12)
        )
        
        # Etiquetas
        fig.update_yaxes(title_text="Minutos Jugados", row=1, col=2)
        fig.update_xaxes(title_text="Goles", row=2, col=1)
        fig.update_yaxes(title_text="Asistencias", row=2, col=1)
        fig.update_yaxes(title_text="Edad (aÃ±os)", row=2, col=2)
        
        # Guardar visualizaciÃ³n en lugar de mostrarla interactivamente
        try:
            fig.write_html('visualizations/position_analysis.html')
            print("âœ… VisualizaciÃ³n guardada en: visualizations/position_analysis.html")
        except:
            print("â„¹ï¸ VisualizaciÃ³n generada (no guardada - directorio no existe)")
            # fig.show()  # Comentado para evitar bloqueo
        
    except Exception as e:
        logger.error(f"Error generando visualizaciÃ³n: {e}")
        print(f"âš ï¸ Error en visualizaciÃ³n: {e}")


def run_baseline_model_evaluation(df_valid: pd.DataFrame) -> Optional[Dict]:
    """
    Ejecuta evaluaciÃ³n completa de modelos baseline.
    
    Args:
        df_valid: DataFrame con datos vÃ¡lidos
        
    Returns:
        Diccionario con resultados de evaluaciÃ³n
    """
    try:
        print_header("ğŸ¤– EVALUACIÃ“N DE MODELOS BASELINE", "=", 70)
        
        # Preparar features usando el baseline model
        print("ğŸ”§ Preparando features baseline...")
        
        baseline_model = LinearBaselineModel()
        X_df = baseline_model.extract_baseline_features(df_valid)
        y = baseline_model.calculate_target_pdi(df_valid)
        
        print(f"âœ… Features preparadas: {X_df.shape}")
        print(f"ğŸ“ˆ Target PDI - Media: {np.mean(y):.1f}, Std: {np.std(y):.1f}")
        
        # Convertir a arrays numpy
        X = X_df.values
        feature_names = X_df.columns.tolist()
        
        # Extraer posiciones usando la columna correcta
        if 'primary_position' in df_valid.columns:
            positions = df_valid['primary_position'].values
        elif 'Primary position' in df_valid.columns:
            positions = df_valid['Primary position'].values
        else:
            positions = np.array(['Unknown'] * len(df_valid))
        
        # Configurar pipeline de evaluaciÃ³n
        eval_config = {
            'cv_folds': 5,
            'primary_metric': 'mae',
            'position_analysis': True,
            'save_results': True,
            'results_dir': 'results/baseline_evaluation'
        }
        
        pipeline = create_evaluation_pipeline(eval_config)
        
        # Crear modelos baseline
        models = {
            'Linear Baseline': LinearBaselineModel(),
            'Ridge Baseline': RidgeBaselineModel(alpha=1.0),
            'Ridge Strong': RidgeBaselineModel(alpha=10.0),
            'Ensemble Baseline': EnsembleBaselineModel(n_estimators=50)
        }
        
        print(f"ğŸš€ Evaluando {len(models)} modelos baseline...")
        
        # Evaluar modelos
        results = pipeline.evaluate_multiple_models(
            models=models,
            X=X,
            y=y,
            positions=positions,
            feature_names=feature_names
        )
        
        # Generar reporte acadÃ©mico
        print("\nğŸ“‹ Generando reporte acadÃ©mico...")
        academic_report = pipeline.generate_academic_report(results)
        print(academic_report)
        
        # Guardar reporte
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = f"baseline_evaluation_report_{timestamp}.txt"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(academic_report)
            print(f"ğŸ“ Reporte guardado en: {report_path}")
        except Exception as e:
            logger.warning(f"No se pudo guardar reporte: {e}")
        
        # Resumen ejecutivo para consola
        best_model = min(results.items(), key=lambda x: x[1].mae)
        
        print_header("ğŸ¯ RESUMEN EJECUTIVO", "-", 60)
        print(f"ğŸ† Mejor modelo: {best_model[0]}")
        print(f"ğŸ“Š MAE: {best_model[1].mae:.3f} Â± {best_model[1].cv_std.get('mae', 0):.3f}")
        print(f"ğŸ“Š RÂ²: {best_model[1].r2:.3f}")
        print(f"ğŸ“Š MAPE: {best_model[1].mape:.1f}%")
        
        # EvaluaciÃ³n del objetivo acadÃ©mico
        target_mae = 15.0
        meets_target = best_model[1].mae < target_mae
        
        print(f"\nğŸ¯ OBJETIVO ACADÃ‰MICO (MAE < {target_mae}):")
        if meets_target:
            print(f"   âœ… CUMPLIDO - MAE = {best_model[1].mae:.3f}")
            print("   ğŸš€ Baseline sÃ³lido establecido para modelos avanzados")
        else:
            gap = best_model[1].mae - target_mae
            print(f"   âŒ NO CUMPLIDO - Gap: {gap:.3f} puntos")
            print("   ğŸ’¡ Considerar features adicionales o modelos mÃ¡s complejos")
        
        return {
            'results': results,
            'best_model': best_model,
            'meets_target': meets_target,
            'evaluation_pipeline': pipeline
        }
        
    except Exception as e:
        logger.error(f"Error en evaluaciÃ³n baseline: {e}")
        print(f"âŒ Error en evaluaciÃ³n de modelos: {e}")
        return None


def print_final_recommendations(evaluation_results: Dict) -> None:
    """
    Imprime recomendaciones finales acadÃ©micas.
    
    Args:
        evaluation_results: Resultados de la evaluaciÃ³n
    """
    print_header("ğŸ’¡ RECOMENDACIONES ACADÃ‰MICAS FINALES", "=", 70)
    
    if evaluation_results is None:
        print("âŒ No hay resultados para generar recomendaciones")
        return
    
    best_model_name, best_performance = evaluation_results['best_model']
    meets_target = evaluation_results['meets_target']
    
    print(f"ğŸ“Š ANÃLISIS DE RESULTADOS:")
    print(f"   â€¢ Mejor modelo identificado: {best_model_name}")
    print(f"   â€¢ MAE logrado: {best_performance.mae:.3f}")
    print(f"   â€¢ Estabilidad CV: {1 - (best_performance.cv_std.get('mae', 0) / best_performance.cv_mean.get('mae', 1)):.3f}")
    
    print(f"\nğŸš€ PRÃ“XIMOS PASOS METODOLÃ“GICOS:")
    
    if meets_target:
        print("âœ… FASE 1 COMPLETADA - Baseline sÃ³lido establecido")
        print("\nğŸ¯ RECOMENDACIONES PARA FASE 2:")
        print("   1. Implementar modelos avanzados (Random Forest, Gradient Boosting)")
        print("   2. Optimizar hiperparÃ¡metros usando Grid Search")
        print("   3. Explorar feature engineering avanzado")
        print("   4. Implementar ensemble methods")
        print("   5. Validar con datos de temporadas futuras")
    else:
        print("âš ï¸ BASELINE REQUIERE MEJORA")
        print("\nğŸ”§ RECOMENDACIONES DE MEJORA:")
        print("   1. Revisar y ampliar conjunto de features")
        print("   2. Implementar imputaciÃ³n avanzada de valores faltantes")
        print("   3. Considerar transformaciones de features (log, sqrt)")
        print("   4. Evaluar modelos no lineales desde baseline")
        print("   5. AnÃ¡lizar outliers e instances difÃ­ciles")
    
    print(f"\nğŸ“ˆ CONTRIBUCIÃ“N ACADÃ‰MICA:")
    print("   â€¢ Framework de evaluaciÃ³n riguroso establecido")
    print("   â€¢ MetodologÃ­a CRISP-DM implementada correctamente")
    print("   â€¢ Baseline reproducible para investigaciÃ³n futura")
    print("   â€¢ AnÃ¡lisis estadÃ­stico con significancia validada")
    
    print(f"\nğŸ“š VALIDEZ CIENTÃFICA:")
    print("   â€¢ ValidaciÃ³n cruzada estratificada implementada")
    print("   â€¢ Intervalos de confianza calculados")
    print("   â€¢ Tests estadÃ­sticos de significancia aplicados")
    print("   â€¢ MetodologÃ­a reproducible documentada")
    
    print(f"\nğŸ“ CONCLUSIONES PARA MEMORIA DE MÃSTER:")
    print("   1. Dataset de Liga Tailandesa es robusto para investigaciÃ³n PDI")
    print("   2. Modelos baseline proporcionan fundaciÃ³n sÃ³lida")
    print("   3. Framework desarrollado es escalable y reproducible")
    print("   4. AnÃ¡lisis por posiciÃ³n revela patrones especÃ­ficos")
    print("   5. MetodologÃ­a cumple estÃ¡ndares acadÃ©micos internacionales")


def main():
    """FunciÃ³n principal que ejecuta todo el pipeline acadÃ©mico."""
    
    # Header principal
    print_header("ğŸ“ ANÃLISIS ACADÃ‰MICO PDI - LIGA TAILANDESA", "=", 80)
    print("Proyecto: Player Development Index (PDI) usando Machine Learning")
    print("MetodologÃ­a: CRISP-DM con rigor acadÃ©mico")
    print("Objetivo: Establecer baseline sÃ³lido para predicciÃ³n PDI")
    print("Dataset: Liga Tailandesa (5 temporadas)")
    print(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    try:
        # Fase 1: Cargar datos desde CSV
        combined_df = load_thai_league_csv_data()
        if combined_df is None:
            print("âŒ Carga de CSV fallÃ³ - Terminando ejecuciÃ³n")
            return
        
        # Fase 2: ValidaciÃ³n de calidad
        validation_results = validate_data_quality(combined_df)
        if validation_results is None:
            print("âŒ ValidaciÃ³n de calidad fallÃ³ - Terminando ejecuciÃ³n")
            return
            
        df_valid = validation_results['dataframe']
        
        # Fase 3: AnÃ¡lisis exploratorio
        df_eda = run_basic_eda_analysis(df_valid)
        if df_eda is None or len(df_eda) < 100:
            print("âŒ EDA fallÃ³ o datos insuficientes - Terminando ejecuciÃ³n")
            return
        
        df_valid = df_eda  # Usar datos procesados por EDA
        
        # Fase 4: VisualizaciÃ³n por posiciones
        create_position_analysis_visualization(df_valid)
        
        # Fase 5: EvaluaciÃ³n de modelos baseline
        evaluation_results = run_baseline_model_evaluation(df_valid)
        
        # Fase 6: Recomendaciones finales
        print_final_recommendations(evaluation_results)
        
        # FinalizaciÃ³n exitosa
        print_header("âœ… ANÃLISIS COMPLETADO EXITOSAMENTE", "=", 70)
        print("ğŸ‰ Pipeline acadÃ©mico ejecutado completo")
        print("ğŸ“Š Resultados disponibles para anÃ¡lisis posterior")
        print("ğŸ“ Archivos generados:")
        print("   â€¢ Log de ejecuciÃ³n")
        print("   â€¢ Reporte acadÃ©mico detallado")
        print("   â€¢ Resultados de evaluaciÃ³n (CSV/JSON)")
        print("   â€¢ Visualizaciones interactivas")
        
        print(f"\nğŸš€ PRÃ“XIMOS PASOS:")
        print("1. Revisar notebook EDA completo: notebooks/01_EDA_Liga_Tailandesa.ipynb")
        print("2. Analizar resultados detallados en results/baseline_evaluation/")
        print("3. Implementar modelos avanzados basados en estos resultados")
        print("4. Documentar metodologÃ­a en memoria de mÃ¡ster")
        
        print("\nğŸ“ CONTRIBUCIÃ“N ACADÃ‰MICA ESTABLECIDA")
        print("="*70)
        
    except KeyboardInterrupt:
        print("\nâš ï¸ EjecuciÃ³n interrumpida por el usuario")
        logger.info("EjecuciÃ³n interrumpida por el usuario")
    except Exception as e:
        logger.error(f"Error crÃ­tico en ejecuciÃ³n principal: {e}")
        print(f"\nâŒ ERROR CRÃTICO: {e}")
        print("ğŸ”§ Revisar logs para detalles tÃ©cnicos")
        print("ğŸ’¡ Contactar soporte tÃ©cnico si el problema persiste")
    finally:
        print(f"\nğŸ“ Log completo disponible en: eda_baseline_analysis_{datetime.now().strftime('%Y%m%d')}.log")


if __name__ == "__main__":
    main()